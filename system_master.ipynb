{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up section headers in mipacq text\n",
    "\n",
    "import re, os, glob, path\n",
    "\n",
    "def clean_files():\n",
    "    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/mipacq/quarantine/'\n",
    "    \n",
    "\n",
    "    os.chdir(directory_to_parse)\n",
    "\n",
    "    regex = r\"\\[(.*?)\\]\"\n",
    "\n",
    "    for fname in glob.glob(directory_to_parse + '*.source'):\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        u = t.split('.')[0] + '.txt'\n",
    "\n",
    "        with open(fname) as f:\n",
    "                with open(directory_to_parse + u, 'w') as f2:\n",
    "                    for line in f:\n",
    "                        a = re.compile(regex)\n",
    "                        if a.search(line):\n",
    "                            match = a.findall(line)\n",
    "                            l = len(match)\n",
    "                            for i in range(len(match)):\n",
    "                                l2 = len(match[i])\n",
    "                                t = ''\n",
    "                                for j in range(l2):\n",
    "                                    t += '^'\n",
    "                                line = line.replace(line, t) + '\\n'\n",
    "                        f2.write(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token offset in document\n",
    "\n",
    "def search_tuple(tups, elem):\n",
    "    return filter(lambda tup: elem in tup, tups)\n",
    "\n",
    "def get_token_offset():\n",
    "    import re, os, glob, path\n",
    "    import spacy\n",
    "    import en_core_web_sm\n",
    "\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/data_in/'\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/data_in/'\n",
    "    directory_to_parse = \"/Users/gms/development/nlp/nlpie/data/ensembling-u01/i2b2/source_data/test_data/\"\n",
    "    os.chdir(directory_to_parse)\n",
    "\n",
    "    \n",
    "    #nlp = spacy.load(\"en\")\n",
    "    nlp = en_core_web_sm.load()\n",
    "\n",
    "    for fname in glob.glob(directory_to_parse + '0445.txt'):\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        u = t.split('.')[0] + '.txt'\n",
    "        \n",
    "        # get span of text \n",
    "        with open(directory_to_parse + '0445.txt') as f:\n",
    "            f1 = f.read()\n",
    "            #print(tokens)\n",
    "            doc = nlp(f1)\n",
    "            #print(doc.text)\n",
    "            print([(token.text,token.idx) for token in doc])\n",
    "#get_token_offset()\n",
    "\n",
    "# extract phrase from offset\n",
    "def text_offset_lookup(begin, ntokens, fname):\n",
    "    import re, os, glob, path\n",
    "    import spacy\n",
    "\n",
    "    directory_to_parse = \"/Users/gms/development/nlp/nlpie/data/ensembling-u01/mipacq/source_data/source/\"\n",
    "    os.chdir(directory_to_parse)\n",
    "\n",
    "    #nlp = spacy.load(\"en\")\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    for fname in glob.glob(fname):\n",
    "        \n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        u = t.split('.')[0] + '.source'\n",
    "        text = \"\"\n",
    "        \n",
    "        # get span of text \n",
    "        with open(fname) as f:\n",
    "            f1 = f.read()\n",
    "            doc = nlp(f1)\n",
    "            tokens = [(token.text,token.idx) for token in doc]\n",
    "            hit = list(search_tuple(tokens, begin))\n",
    "            idx = tokens.index(hit[0])\n",
    "            text = tokens[idx: idx + ntokens]\n",
    "            \n",
    "            return text\n",
    "            \n",
    "text = \"noted that she\"\n",
    "n = len(text.split())\n",
    "begin = 438\n",
    "\n",
    "text_offset_lookup(begin, n, '5024581165-5.source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for UIMA systems\n",
    "class AnnotationSystems(object):\n",
    "    \"\"\"\n",
    "    CAS XMI Annotations of interest\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.biomedicus_dir = \"biomedicus_out/\"\n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\",\n",
    "                                 \"biomedicus.v2.Negated\"]\n",
    "                                 #\"biomedicus.v2.Acronym\",\n",
    "                                 #\"biomedicus.v2.DictionaryTerm\",\n",
    "                                 #\"biomedicus.v2.Historical\"]\n",
    "        \n",
    "        \n",
    "        self.clamp_dir = \"clamp_out/\"\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.syntax.ConllDependencyNode\",\n",
    "                             \"edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\"]\n",
    "        \n",
    "        \n",
    "        self.ctakes_dir = \"ctakes_out/\"\n",
    "        self.ctakes_types = ['ctakes_mentions_all']#\"org.apache.ctakes.typesystem.type.textspan.Sentence\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.MedicationMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.ProcedureMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.refsem.UmlsConcept\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.SignSymptomMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention\"]\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.MeasurementAnnotation\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.EventMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.EntityMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.Predicate\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.syntax.WordToken\"]\n",
    "        \n",
    "        self.metamap_dir = \"metamap_out/\"\n",
    "        self.metamap_types = [#\"org.metamap.uima.ts.Utterance\",\n",
    "                              #\"org.metamap.uima.ts.Span\",\n",
    "                              #\"org.metamap.uima.ts.Phrase\"]\n",
    "                              \"org.metamap.uima.ts.Candidate\"]\n",
    "                              #\"org.metamap.uima.ts.CuiConcept\",\n",
    "                              #\"org.metamap.uima.ts.Negation\"]\n",
    "                \n",
    "        self.inception_dir = \"/Users/gms/development/nlp/nlpie/data/irr_mts/\"\n",
    "        self.inception_types = [\"webanno.custom.Term\"]\n",
    "           \n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.biomedicus_dir = \"biomedicus_out/\"\n",
    "        self.biomedicus_types = [#\"biomedicus.v2.UmlsConcept\"]\n",
    "                                  #\"biomedicus.v2.Negated\"\n",
    "                                 \"biomedicus.v2.Acronym\",\n",
    "                                 \"biomedicus.v2.DictionaryTerm\",\n",
    "                                 \"biomedicus.v2.Historical\"]\n",
    "        \n",
    "        \n",
    "        self.clamp_dir = \"clamp_out/\"\n",
    "        #self.clamp_types = [#\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "                             #\"org.apache.ctakes.typesystem.type.syntax.ConllDependencyNode\",\n",
    "                             #\"edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\"]\n",
    "        \n",
    "        \n",
    "        self.ctakes_dir = \"ctakes_out/\"\n",
    "        self.ctakes_types = [\"org.apache.ctakes.typesystem.type.textspan.Sentence\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.MedicationMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.ProcedureMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.refsem.UmlsConcept\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.SignSymptomMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention\"]\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.MeasurementAnnotation\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.EventMention\",\n",
    "                             #\"org.apache.ctakes.typesystem.type.textsem.EntityMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.Predicate\",\n",
    "                             \"org.apache.ctakes.typesystem.type.syntax.WordToken\"]\n",
    "        \n",
    "        self.metamap_dir = \"metamap_out/\"\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Utterance\",\n",
    "                              \"org.metamap.uima.ts.Span\",\n",
    "                              \"org.metamap.uima.ts.Phrase\"]\n",
    "                              #\"org.metamap.uima.ts.Candidate\"]\n",
    "                              #\"org.metamap.uima.ts.CuiConcept\",\n",
    "                              #\"org.metamap.uima.ts.Negation\"]\n",
    "                              \n",
    "        '''\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "            output = self.biomedicus_dir\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "            output = self.clamp_dir\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "            output = self.ctakes_dir\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "            output = self.metamap_dir\n",
    "        \n",
    "        elif system == 'inception':\n",
    "            types = self.inception_types\n",
    "            output = self.inception_dir       \n",
    "            \n",
    "        return types, view, output\n",
    "    \n",
    "annSys = AnnotationSystems()\n",
    "\n",
    "# extract attributes from cas Annotation object\n",
    "def get_attribs(v):\n",
    "    attribs = []\n",
    "    for sentence in v:\n",
    "        #print(sentence)\n",
    "        for s in sentence.__dir__():\n",
    "            if '__' not in s:\n",
    "                if s not in attribs:\n",
    "                    #print(s)\n",
    "                    attribs.append(s)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return attribs\n",
    "    \n",
    "#annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dkpro-cassis -> inception\n",
    "import os\n",
    "from cassis import *\n",
    "import pandas as pd\n",
    "import re, os, glob, path\n",
    "\n",
    "def get_annotations():\n",
    "    \n",
    "    systems = [\"inception\"]\n",
    "\n",
    "    #fname = 'alber475.xmi'\n",
    "\n",
    "    for system in systems:\n",
    "        types, v, dir_to_parse = AnnotationSystems().get_system_type(system) # system types for iterable\n",
    "        typesystem_dir = \"/Users/gms/development/nlp/nlpie/data/irr_mts/\"\n",
    "        \n",
    "        print(dir_to_parse, system)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        for fname in glob.glob(dir_to_parse + '**/' + '*.xmi'):\n",
    "\n",
    "            # get filename and use for processed output filename\n",
    "            file = os.path.basename(fname) # file w/ full path\n",
    "            annotator = file.split('.')[0] # annotator\n",
    "            case = fname.split('/')[-2] # case\n",
    "\n",
    "            print(annotator, case)\n",
    "\n",
    "            with open(typesystem_dir + '/TypeSystem.xml', 'rb') as f:\n",
    "                typesystem = load_typesystem(f)\n",
    "\n",
    "            for t in types:\n",
    "                print(t, annotator)\n",
    "\n",
    "                with open(fname, 'rb') as f:\n",
    "                    cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "                view = cas.get_view(v)\n",
    "\n",
    "\n",
    "                d = {}\n",
    "                attribs = get_attribs(view.select(t))\n",
    "                # only parse if type exists in file\n",
    "                if view.select(t):\n",
    "                    for sentence in view.select(t):\n",
    "                        # write attributes out to dictionary\n",
    "                        for i in range(len(attribs)):\n",
    "                            key = attribs[i]\n",
    "                            # helper method to get val for given key\n",
    "                            val = sentence.__getattribute__(attribs[i])\n",
    "                        \n",
    "                            if isinstance(val, list):\n",
    "                                val = ' '.join(val) # flatten list to space delimited variable\n",
    "                        \n",
    "                            d[key] = val\n",
    "                            d[\"case\"] = case\n",
    "                            d[\"annotator\"] = annotator\n",
    "\n",
    "                            # write out full annotation to df row\n",
    "                            if i == len(attribs) - 1:\n",
    "                                \n",
    "                                # concat to existing df\n",
    "                                frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                                df = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    \n",
    "print(get_annotations())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# parse system annotations\n",
    "def main():\n",
    "    import os, glob\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    #import json\n",
    "    from superjson import json\n",
    "    \n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from sqlalchemy.sql import text\n",
    "    from cassis import load_typesystem, load_cas_from_xmi\n",
    "\n",
    "    # connection string\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/i2b2', pool_pre_ping=True)\n",
    "    systems = [\"clamp\", \"biomedicus\"]\n",
    "    #systems = [\"clamp\", \"ctakes\"]\n",
    "    #systems = [\"metamap\"]\n",
    "    #systems = [\"biomedicus\"]\n",
    "    # corpora = [\"i2b2\", \"mipacq\", \"mimic\"]\n",
    "    corpora = [\"i2b2\"]\n",
    "    parse_to_sql = True\n",
    "    \n",
    "    i = 0\n",
    "    if parse_to_sql:\n",
    "        \n",
    "        for corpus in corpora:\n",
    "\n",
    "            for system in systems:\n",
    "\n",
    "                print(\"SYSTEM:\", system, corpus)\n",
    "\n",
    "                types, view_, output = annSys.get_system_type(system)\n",
    "                # parse directory\n",
    "\n",
    "                if corpus in [\"i2b2\", \"mipacq\"]:\n",
    "                    path = '/Users/gms/development/nlp/nlpie/data/amicus-u01/analysis/' + corpus + '/'  #+ 'rerun_post_validation/' #data_to_analyze/all/'\n",
    "                    \n",
    "                else:\n",
    "                    path = '/Users/gms/development/nlp/nlpie/data/mimic/'\n",
    "\n",
    "                directory_to_parse = path + output\n",
    "\n",
    "                typesystem_dir = \"/Users/gms/development/nlp/nlpie/data/amicus-u01/typesystems/\" + system\n",
    "\n",
    "                # load cas typesystem\n",
    "                with open(typesystem_dir + '/TypeSystem.xml', 'rb') as f:\n",
    "                    typesystem = load_typesystem(f)\n",
    "\n",
    "                for fname in glob.glob(directory_to_parse + '*.txt.xmi'):\n",
    "\n",
    "                    file = os.path.basename(fname)\n",
    "                    u = file.split('.')[0].replace('-v1-v2','').replace('-v1','').replace('-v2','')\n",
    "\n",
    "                    #if file not in skip_these:\n",
    "\n",
    "                    #if i%10 == 0:\n",
    "                    print(u, file)\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "                    # load cas\n",
    "                    with open(directory_to_parse + file, 'rb') as f:\n",
    "                        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "                    # load cas view\n",
    "                    view = cas.get_view(view_)\n",
    "\n",
    "                    # sofa -> db\n",
    "                    def write_sofa(u):\n",
    "                        d = {}\n",
    "                        d[\"note_id\"] = str(u)\n",
    "                        d[\"sofa\"] = view.sofa_string\n",
    "                        d[\"corpus\"] = corpus\n",
    "\n",
    "                        # does it exist?\n",
    "                        if engine.dialect.has_table(engine, \"sofas\"):\n",
    "                            sql = text(\"SELECT * FROM test.sofas WHERE note_id = :e1\")\n",
    "                            resp = engine.execute(sql, e1=u).fetchall()\n",
    "                        else:\n",
    "                            resp = []\n",
    "\n",
    "                        if len(resp) == 0:            \n",
    "                            pd.DataFrame(d, index=[0]).to_sql(\"sofas\", engine, if_exists=\"append\")  \n",
    "\n",
    "                    write_sofa(u)\n",
    "\n",
    "                    for t in types:\n",
    "                        attribs = get_attribs(view.select(t))\n",
    "                        annotation_type = t\n",
    "                        x = t.split('.')\n",
    "                        table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                        # Annotation object -> dataframe\n",
    "                        def get_df(v, attribs):\n",
    "                        #def get_df(v, attribs, t, table_name):\n",
    "                            d = {}\n",
    "                            df = pd.DataFrame()\n",
    "\n",
    "                            # only parse if type exists in file\n",
    "                            if view.select(t):\n",
    "                                for sentence in view.select(t):\n",
    "                                    for i in range(len(attribs)):\n",
    "                                        key = attribs[i]\n",
    "                                        val = sentence.__getattribute__(attribs[i])\n",
    "                                        if isinstance(val, list):\n",
    "                                            val = ' '.join(val)\n",
    "                                        d[key] = val\n",
    "                                        if i == len(attribs) - 1:\n",
    "\n",
    "                                            # compress object for db storage\n",
    "                                            #d[\"attributes\"] = json.dumps(d, compress=True)\n",
    "\n",
    "                                            frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                                            df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "                            df[\"system\"] = system\n",
    "                            df[\"type\"] = annotation_type\n",
    "                            df[\"note_id\"] = u\n",
    "                            df[\"corpus\"] = corpus\n",
    "                            df[\"filename\"] = fname\n",
    "                            #df.to_sql(table_name, engine, if_exists=\"append\")  \n",
    "                            return df\n",
    "\n",
    "                        annotations = get_df(view.select(t), attribs)\n",
    "\n",
    "                        # write to database\n",
    "\n",
    "                        if not annotations.empty:\n",
    "                            annotations.to_sql(table_name, engine, if_exists=\"append\") \n",
    "   \n",
    "    # write out annotations for non-cui tables\n",
    "    else:\n",
    "        \n",
    "        sys_ann_other = pd.DataFrame()\n",
    "        for system in systems:\n",
    "                \n",
    "            types, view_, output = annSys.get_system_type(system)\n",
    "            print(\"SYSTEM:\", system)\n",
    "           \n",
    "            for t in types:\n",
    "\n",
    "                x = t.split('.')\n",
    "                table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                sql = \"SELECT * FROM test.\" + table_name \n",
    "                df = pd.read_sql(sql, engine)\n",
    "\n",
    "                cols_to_keep = ['begin', 'end', 'type', 'system', 'note_id', 'corpus', 'filename']\n",
    "                print(system, t, table_name, list(df[cols_to_keep].columns.values))\n",
    "                \n",
    "                frames = [ sys_ann_other, df[cols_to_keep] ]\n",
    "                sys_ann_other = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        print(sys_ann_other.drop_duplicates())\n",
    "        sys_ann_other.drop_duplicates().to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_mipacq_others.csv')\n",
    "\n",
    "    print(\"done!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \n",
    "import pandas as pd\n",
    "#df = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq.csv')\n",
    "\n",
    "    #df[(df[\"note_id\"] == '5024581165-5') & (df[\"type\"] == 'org.metamap.uima.ts.Candidate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables for cTAKES UMLS concept -> mention table\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "def mk_ctakes_concepts(sql, table_name):\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "\n",
    "    # MetaMap\n",
    "    b = pd.DataFrame(df.cuiConcepts.str.split(' ').tolist(), index=df.cuiConcepts).stack()\n",
    "    b = b.reset_index()[[0, 'cuiConcepts']] # var1 variable is currently labeled 0\n",
    "    b.columns = ['linked_id', 'cuiConcepts'] # renaming var1\n",
    "    \n",
    "    # CTAKES:\n",
    "     \n",
    "    #b = pd.DataFrame(df.ontologyConceptArr.str.split(' ').tolist(), index=df.ontologyConceptArr).stack()\n",
    "    #b = b.reset_index()[[0, 'ontologyConceptArr']] # var1 variable is currently labeled 0\n",
    "    #b.columns = ['linked_id', 'ontologyConceptArr'] # renaming var1\n",
    "    \n",
    "\n",
    "    c = pd.merge(df, b)\n",
    "   \n",
    "    c.to_sql(table_name, engine, if_exists=\"replace\") \n",
    "\n",
    "    print(c[0:2])\n",
    "\n",
    "''' TABLES to make\n",
    "sql = \"SELECT * FROM test.met_org_negation\"\n",
    "table_name = 'mm_negation'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "'''\n",
    "'''\n",
    "sql = \"SELECT * FROM test.cta_disease\"\n",
    "table_name = 'cTAKES_disease'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_med\"\n",
    "table_name = 'cTAKES_medication'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_proc\"\n",
    "table_name = 'cTAKES_procedure'\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_sign_symptom\"\n",
    "table_name = 'cTAKES_sign_symptom'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_anatomical_site\"\n",
    "table_name = 'cTAKES_anatomical_site'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix XMI, adding \"id\" for those with linked features\n",
    "\n",
    "def add_attribute_sys_type(regexpatterns):\n",
    "    import re, os, glob, path\n",
    "    import regex\n",
    "\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/'\n",
    "\n",
    "    #for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/period2/*.txt\"):\n",
    "\n",
    "    for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/rerun_post_validation/metamap_out/*.txt.xmi\"):\n",
    "\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        cd = os.path.dirname(fname)\n",
    "        u = t.split('.')[0] + '-v2.txt.xmi'\n",
    "        #print(t, cd)\n",
    "\n",
    "        #print(t)\n",
    "        with open(fname) as f:\n",
    "            with open(cd + '/' + u, 'w') as f2:\n",
    "                for line in f:\n",
    "                    for r in regexpatterns:\n",
    "                        line = re.sub(r, r + ' id=\"0\"', line)\n",
    "                    f2.write(line)\n",
    "    \n",
    "\n",
    "#regexpatterns = [r\"refsem:UmlsConcept\"]\n",
    "#regexpatterns = [r\"ts2:CuiConcept\"]\n",
    "#regexpatterns = [r\"ts2:Negation\"]\n",
    " \n",
    "#add_attribute_sys_type(regexpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dkpro-cassis\n",
    "import os\n",
    "from cassis import *\n",
    "import pandas as pd\n",
    "\n",
    "typesystem_dir = \"/Users/gms/development/nlp/nlpie/data/irr_mts/\"\n",
    "dir_test = '/Users/gms/development/nlp/nlpie/data/irr_mts/92_1664/'\n",
    "\n",
    "with open(typesystem_dir + 'TypeSystem.xml', 'rb') as f:\n",
    "    typesystem = load_typesystem(f)\n",
    "\n",
    "system = [\"inception\"]\n",
    "\n",
    "for sys in systems:\n",
    "        types, _, _ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "        for t in types:\n",
    "            print(t)\n",
    "\n",
    "# # add missing types\n",
    "# t = typesystem.create_type(name='org.apache.uima.examples.SourceDocumentInformation', supertypeName='uima.tcas.Annotation')\n",
    "# typesystem.add_feature(t, name='uri', rangeTypeName='uima.cas.String')\n",
    "# typesystem.add_feature(t, name=\"offsetInSource\", rangeTypeName=\"uima.cas.Integer\")\n",
    "# typesystem.add_feature(t, name=\"documentSize\", rangeTypeName=\"uima.cas.Integer\")\n",
    "# typesystem.add_feature(t, name=\"lastSegment\", rangeTypeName=\"uima.cas.Integer\")\n",
    "\n",
    "# t = typesystem.create_type(name=\"uima.tcas.DocumentAnnotation\", supertypeName=\"uima.tcas.Annotation\")\n",
    "# typesystem.add_feature(t, name=\"language\", rangeTypeName=\"uima.cas.String\")\n",
    "    \n",
    "# t = typesystem.create_type(name='uima.noNamespace.ArtifactID', supertypeName='uima.tcas.Annotation')\n",
    "# typesystem.add_feature(t, name='artifactID', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "# t = typesystem.create_type(name='uima.noNamespace.ArtifactMetadata', supertypeName='uima.tcas.Annotation')\n",
    "# typesystem.add_feature(t, name='key', rangeTypeName='uima.cas.String')\n",
    "# typesystem.add_feature(t, name='value', rangeTypeName='uima.cas.String')\n",
    "\n",
    "fname = 'alber475.xmi'\n",
    "with open(dir_test + fname, 'rb') as f:\n",
    "    cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "#view = cas.get_view('Analysis')\n",
    "view = cas.get_view('_InitialView')\n",
    "\n",
    "\n",
    "#print([x for x in view.select_all()])\n",
    "#print([x for x in view.select(\"biomedicus.v2.UmlsConcept\")])\n",
    "#print([x for x in view.select(\"webanno.custom.Term\")])\n",
    "#print([x for x in view.select(\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\")])\n",
    "def get_attribs(v):\n",
    "    attribs = []\n",
    "    for sentence in v:\n",
    "        #print(sentence)\n",
    "        for s in sentence.__dir__():\n",
    "            if '__' not in s:\n",
    "                if s not in attribs:\n",
    "                    #print(s)\n",
    "                    attribs.append(s)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return attribs\n",
    "    \n",
    "#annSys = AnnotationSyste\n",
    "df = pd.DataFrame()\n",
    "d = {}\n",
    "# only parse if type exists in file\n",
    "\n",
    "attribs = get_attribs(view.select(\"webanno.custom.Term\"))\n",
    "if view.select(\"webanno.custom.Term\"):\n",
    "    for sentence in view.select(\"webanno.custom.Term\"):\n",
    "        for i in range(len(attribs)):\n",
    "            key = attribs[i]\n",
    "            val = sentence.__getattribute__(attribs[i])\n",
    "            if isinstance(val, list):\n",
    "                val = ' '.join(val)\n",
    "            d[key] = val\n",
    "            if i == len(attribs) - 1:\n",
    "\n",
    "                # compress object for db storage\n",
    "                #d[\"attributes\"] = json.dumps(d, compress=True)\n",
    "\n",
    "                frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "#org.apache.ctakes.typesystem.type.textsem.MedicationMention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dkpro-cassis\n",
    "from cassis import *\n",
    "def test_dkpro(fname, dir_test, ts_test, view_name):\n",
    "    with open(ts_test + 'TypeSystem.xml', 'rb') as f:\n",
    "        typesystem = load_typesystem(f)\n",
    "    with open(dir_test + fname, 'rb') as f:\n",
    "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "    view = cas.get_view(view_name)\n",
    "    print([x for x in view.select_all()])\n",
    "    #print([x for x in view.select(\"org.apache.ctakes.typesystem.type.refsem.UmlsConcept\")])\n",
    "\n",
    "\n",
    "# dir_test = '/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/metamap_out/'\n",
    "# view_name = \"_InitialView\"\n",
    "# ts_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/typesystems/metamap/\"\n",
    "# fname = '3283236649-v1.txt.xmi'\n",
    "# test_dkpro(fname, dir_test, ts_test, view_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for mipacq corpora\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def unnesting(df, explode):\n",
    "    idx=df.index.repeat(df[explode[0]].str.len())\n",
    "    df1=pd.concat([pd.DataFrame({x:np.concatenate(df[x].values)} )for x in explode],axis=1)\n",
    "    df1.index=idx\n",
    "    return df1.join(df.drop(explode,1),how='left')\n",
    "\n",
    "def class_to_dataframe(className, t):\n",
    "    # get dictionary element and flatten into df\n",
    "    if len(className) > 0:\n",
    "        df = pd.io.json.json_normalize(className)\n",
    "        df[\"file\"] = t\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "def stack_span(annotations):\n",
    "    # case where multiple annotations embedded in signle xml item:\n",
    "    d = {}\n",
    "    unstacked = pd.DataFrame()\n",
    "    \n",
    "    # rename to sane names:\n",
    "    \"\"\"Index(['annotator.$', 'annotator.@id', 'creationDate.$', 'mention.@id', 'span',\n",
    "       'span.@end', 'span.@start', 'spannedText.$', 'file'],\n",
    "      dtype='object')\"\"\"\n",
    "    \n",
    "    \n",
    "    if 'span' in annotations.columns:\n",
    "        temp = annotations.rename(columns={'mention.@id': 'mentionId',\n",
    "                                                   'annotator.@id': 'annotatorId',\n",
    "                                                   'spannedText.$': 'text',\n",
    "                                                   'span.@end': 'end',\n",
    "                                                   'span.@start': 'start',\n",
    "                                                   'annotator.$': 'annotator'}).copy() \n",
    "        \n",
    "        for row in temp.itertuples():\n",
    "            if 'span' in row._fields:\n",
    "                if isinstance(row.span, list):\n",
    "\n",
    "                    for item in row.span:\n",
    "                        d[\"mention.@id\"] = row.mentionId\n",
    "                        d[\"spannedText.$\"] = row.text\n",
    "                        d[\"span.@start\"] = item[\"@start\"]\n",
    "                        d[\"span.@end\"] = item[\"@end\"]\n",
    "                        d[\"annotator.@id\"] = row.annotatorId\n",
    "                        d[\"annotator.$\"] = row.annotator\n",
    "                        d[\"file\"] = row.file\n",
    "                        frames = [ annotations, pd.DataFrame(d, index=[0]) ]\n",
    "                        annotations = pd.concat(frames, ignore_index=True, sort=False)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return annotations\n",
    "        \n",
    "\n",
    "class ReferenceAnnotations(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 annotations, \n",
    "                 classes, \n",
    "                 complexes, \n",
    "                 strings,\n",
    "                 booleans = None):\n",
    "        \n",
    "        self = self\n",
    "        self.annotations = annotations\n",
    "        self.classes = classes\n",
    "        self.complexes = complexes\n",
    "        self.strings = strings\n",
    "        self.booleans = booleans\n",
    "        \n",
    "    def is_instance_complex_negation(self):\n",
    "\n",
    "        odds_n_sods = pd.DataFrame()\n",
    "\n",
    "        # iterate over ann and class df to determine whether complex: if not complex then is it boolean?\n",
    "        for index, row in self.annotations.iterrows():\n",
    "            for idx, r in self.classes.iterrows():\n",
    "                # match annotation to class\n",
    "                if row[\"mention.@id\"] == r['@id']:\n",
    "\n",
    "                    # should be a list associated with key, but not necessarily\n",
    "                    if 'hasSlotMention' in self.classes:\n",
    "\n",
    "                        # get list of ids:\n",
    "                        ids = self.classes.loc[self.classes[\"@id\"] == (row[\"mention.@id\"]), \n",
    "                                               'hasSlotMention'].values[0]\n",
    "\n",
    "                        # for negation there will only be 2-elements in the list: the first maps to a stringSlotMention, the second to a booleanSlotMention\n",
    "                        # need to test not in complexSlotMention\n",
    "                        # also case for two stringSlotMentions where one is text other is degree of certainty\n",
    "\n",
    "                        # if not list: do nothing!\n",
    "                        if isinstance(ids, list) :\n",
    "                            notComplex = True\n",
    "                            notBoolean = True\n",
    "                            notDegree = True\n",
    "\n",
    "                            val = '' \n",
    "                            for i in ids:\n",
    "\n",
    "                                val += ' ' + i[\"@id\"]\n",
    "                                # these are complex relationships\n",
    "                                if not self.complexes[self.complexes[\"@id\"] == i[\"@id\"]].empty:\n",
    "                                    notComplex = False\n",
    "                                else:\n",
    "                                    if not self.booleans is None:\n",
    "                                        # these are boolean/negations\n",
    "                                        if notComplex and not self.booleans.empty:\n",
    "                                            if not self.booleans[self.booleans[\"@id\"] == i[\"@id\"]].empty:\n",
    "                                                notBoolean = False\n",
    "\n",
    "                                    # these are degree of certaintly\n",
    "                                    if notBoolean and notComplex:\n",
    "                                        if not self.strings[self.strings[\"@id\"] == i[\"@id\"]].empty:\n",
    "                                            notDegree = False\n",
    "\n",
    "                            # write to summary df\n",
    "                            if not notComplex:\n",
    "                                out = self.classes[self.classes[\"@id\"] == (row[\"mention.@id\"])] # complex_df[complex_df[\"@id\"] == t[\"@id\"]].copy()\n",
    "                                if not out.empty:\n",
    "                                    d  = out.to_dict('record')\n",
    "                                    d[0][\"classType\"] = 'complex'\n",
    "                                    d[0][\"linked.ids\"] = val\n",
    "                                    d[0][\"class.id\"] = row[\"mention.@id\"]\n",
    "                                    #frames = [ odds_n_sods, pd.DataFrame(d, index=[0]) ]\n",
    "                                    #odds_n_sods = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "                            elif not notBoolean:\n",
    "                                out = self.classes[self.classes[\"@id\"] == (row[\"mention.@id\"])] #test #boolean_df[boolean_df[\"@id\"] == t[\"@id\"]].copy()\n",
    "                                if not out.empty:\n",
    "                                    d  = out.to_dict('record')\n",
    "                                    d[0][\"classType\"] = \"boolean\"\n",
    "                                    d[0][\"linked.ids\"] = val\n",
    "                                    d[0][\"class.id\"] = row[\"mention.@id\"]\n",
    "                                    #frames = [ odds_n_sods, pd.DataFrame(d, index=[0]) ]\n",
    "                                    #odds_n_sods = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "                            elif not notDegree:\n",
    "                                out = self.classes[self.classes[\"@id\"] == (row[\"mention.@id\"])] #test # string_df[string_df[\"@id\"] == t[\"@id\"]].copy()\n",
    "                                if not out.empty:\n",
    "                                    d  = out.to_dict('record')\n",
    "                                    d[0][\"classType\"] = \"degree\"\n",
    "                                    d[0][\"linked.ids\"] = val\n",
    "                                    d[0][\"class.id\"] = row[\"mention.@id\"]\n",
    "\n",
    "                            if not out.empty:\n",
    "                                frames = [ odds_n_sods, pd.DataFrame(d, index=[0]) ]\n",
    "                                odds_n_sods = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "        #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "        #    print(odds_n_sods)           \n",
    "\n",
    "        return odds_n_sods     \n",
    "\n",
    "    # update string df with linked ids and class type for bool, complex, or degree of certainty\n",
    "    def update_str(self, oas):\n",
    "\n",
    "        for index, row in oas.iterrows():\n",
    "            for i, r in self.iterrows():\n",
    "\n",
    "                test = row[\"linked.ids\"]\n",
    "\n",
    "                if r[\"@id\"] in test:\n",
    "                    \n",
    "                    # df.loc[df.filename == 'test2.dat', 'n'] = df2[df2.filename == 'test2.dat'].loc[0]['n']\n",
    "                    #self['classType'] = self.loc[self['@id'] == r[\"@id\"], ['classType']] = row[\"classType\"]\n",
    "                    #self['linked.ids'] = self.loc[self['@id'] == r[\"@id\"], ['linked.ids']] = row[\"linked.ids\"]\n",
    "                    \n",
    "                    #df.loc[df['item'] == 'apple', 'freshness'] = apple\n",
    "                    self.loc[self['@id'] == r[\"@id\"], ['classType']] = row[\"classType\"]\n",
    "                    #self.loc[self['@id'] == r[\"@id\"], ['linked.ids']] = row[\"linked.ids\"]\n",
    "                    #self.loc[self['@id'] == r[\"@id\"], ['class.id']] = row[\"@id\"]\n",
    "                    #self['corpus'] = 'MiPACQ'\n",
    "\n",
    "        #print('s:', self[[\"classType\", \"linked.ids\"]][(self[\"classType\"]  == 'complex') | (self[\"classType\"]  == 'boolean') | (self[\"classType\"]  == 'degree')] )\n",
    "                    #print(\"out test:\", r[\"@id\"], row[\"linked.ids\"], row[\"classType\"])\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "def parse_mipacq_reference():\n",
    "    # parse mipacq reference standard\n",
    "    import glob, os\n",
    "    import pandas as pd\n",
    "    from xml.etree.ElementTree import fromstring\n",
    "    from xmljson import badgerfish as bf\n",
    "    import json\n",
    "    from json import dumps\n",
    "    from pandas.io.json import json_normalize\n",
    "\n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from sqlalchemy.sql import text\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test')\n",
    "    dir_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/mipacq/source_data/reference/\"\n",
    "\n",
    "    good_files = []\n",
    "    no_data = []\n",
    "    processed_files = []\n",
    "    empty_annotations = []\n",
    "    missing_key = []\n",
    "\n",
    "    # TEST CASES -> bad: 60891 good: \n",
    "    #for fname in glob.glob(dir_test + '*.xml'):\n",
    "    # test for degreeness: 0580150767-0\n",
    "    for fname in glob.glob(dir_test + '*.xml'):\n",
    "\n",
    "        #if fname is not \"2889522952-2.xml\":\n",
    "            # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "\n",
    "        case = t.replace('-v1','').split('.')\n",
    "        print(t)\n",
    "        with open(dir_test + t) as f:\n",
    "            f1 = f.read()\n",
    "\n",
    "        data = dumps(bf.data(fromstring(f1)))\n",
    "        d = json.loads(data)\n",
    "\n",
    "        ann = d.get(\"annotations\").get(\"annotation\")\n",
    "        annSuper = d.get(\"annotations\")\n",
    "        classMention = annSuper.get(\"classMention\")\n",
    "        stringMention = annSuper.get(\"stringSlotMention\")\n",
    "        booleanMention = annSuper.get(\"booleanSlotMention\")\n",
    "        complexMention = annSuper.get(\"complexSlotMention\")\n",
    "\n",
    "        if ann is None:\n",
    "            empty_annotations.append(t)\n",
    "        else:  \n",
    "            annotations = class_to_dataframe(ann, case[0])\n",
    "            \n",
    "            # unpack list of spans to stack in multiple rows\n",
    "            annotations = stack_span(annotations)\n",
    "\n",
    "            if classMention:\n",
    "                classes = class_to_dataframe(classMention, case[0])\n",
    "            if stringMention:\n",
    "                strings = class_to_dataframe(stringMention, case[0])\n",
    "            if booleanMention:\n",
    "                booleans = class_to_dataframe(booleanMention, case[0])\n",
    "            if complexMention:\n",
    "                complexes = class_to_dataframe(complexMention, case[0])\n",
    "\n",
    "            ann_to_class = pd.merge(annotations, \n",
    "                                    classes, \n",
    "                                    left_on='mention.@id', \n",
    "                                    right_on='@id')\n",
    "\n",
    "            if 'hasSlotMention.@id' in ann_to_class.columns:\n",
    "\n",
    "                # instantiate \n",
    "                if not booleanMention:\n",
    "                    booleans = None\n",
    "                refAnn = ReferenceAnnotations(annotations, \n",
    "                                              classes, \n",
    "                                              complexes, \n",
    "                                              strings, \n",
    "                                              booleans)\n",
    "\n",
    "                oas = ReferenceAnnotations.is_instance_complex_negation(refAnn)\n",
    "\n",
    "\n",
    "                # update string_df with attributes and keys:\n",
    "                strings[\"classType\"] = np.nan\n",
    "\n",
    "                analyticAnn = (strings)\n",
    "\n",
    "                out = ReferenceAnnotations.update_str(analyticAnn, oas)\n",
    "\n",
    "                # this only gives non intersting stuff:\n",
    "                ann_to_string = pd.merge(ann_to_class, \n",
    "                                         #strings,\n",
    "                                         out,\n",
    "                                         left_on='hasSlotMention.@id', \n",
    "                                         right_on='@id')\n",
    "\n",
    "            else:\n",
    "                missing_key.append(t)\n",
    "\n",
    "            cols_to_keep = [\"mention.@id\", \n",
    "                            \"span.@end\", \n",
    "                            \"span.@start\", \n",
    "                            \"spannedText.$\", \n",
    "                            \"hasSlotMention.@id\", \n",
    "                            \"mentionClass.$\", \n",
    "                            \"mentionClass.@id\", \n",
    "                            \"mentionSlot.@id\", \n",
    "                            \"stringSlotMentionValue.@value\", \n",
    "                            \"file\"]\n",
    "\n",
    "            ann_to_string = ann_to_string[cols_to_keep]\n",
    "\n",
    "            processed_files.append(t)\n",
    "\n",
    "            if oas.empty or strings.empty:\n",
    "                empty_annotations.append(t)\n",
    "            else:\n",
    "                if \"hasSlotMention\" in ann_to_class.columns:\n",
    "                    cls = classes[classes['hasSlotMention'].notnull()]\n",
    "                    s=unnesting(cls,['hasSlotMention']).reset_index()      \n",
    "\n",
    "                    # https://stackoverflow.com/questions/35711059/extract-dictionary-value-from-column-in-data-frame\n",
    "                    s['linked.id'] = s.hasSlotMention.apply(pd.Series)\n",
    "\n",
    "                    ann_to_cls = pd.merge(ann_to_class[~ann_to_class[\"span.@start\"].isnull()], \n",
    "                                          s,\n",
    "                                          left_on='@id', \n",
    "                                          right_on='@id')\n",
    "\n",
    "                    #print(ann_to_cls[ann_to_cls[\"span.@start\"].isnull()])\n",
    "                    mess = pd.merge(ann_to_cls, \n",
    "                                          oas,\n",
    "                                          left_on='@id', \n",
    "                                          right_on='@id')\n",
    "                    \n",
    "                    a_real_mess = pd.merge(mess,\n",
    "                                           strings,\n",
    "                                           left_on=\"linked.id\",\n",
    "                                           right_on=\"@id\")\n",
    "\n",
    "                    if not a_real_mess.empty:\n",
    "\n",
    "                        cols_to_keep = ['mention.@id',  \n",
    "                                        'span.@end', \n",
    "                                        'span.@start', \n",
    "                                        'spannedText.$',  \n",
    "                                        'mentionClass.$_x',\n",
    "                                        'mentionClass.@id_x', \n",
    "                                        'index', \n",
    "                                        'linked.id', \n",
    "                                        'class.id', \n",
    "                                        'mentionClass.$', \n",
    "                                        'mentionClass.@id', \n",
    "                                        'mentionSlot.@id',\n",
    "                                        'stringSlotMentionValue.@value', \n",
    "                                        'file', \n",
    "                                        'classType_y', \n",
    "                                        'linked.ids']\n",
    "\n",
    "                        a_real_mess = a_real_mess[cols_to_keep]\n",
    "\n",
    "                        a_real_mess = a_real_mess.rename(columns={'mentionClass.$_x': 'mentionClass.$',\n",
    "                                                                 #'hasSlotMention_x': 'hasSlotMention',\n",
    "                                                                  'mentionClass.@id_x': 'mentionClass.@id',\n",
    "                                                                  'classType_y': 'classType'})    \n",
    "                        \n",
    "                        #print(a_real_mess.columns, a_real_mess[a_real_mess['span.@start'].isnull()])\n",
    "                        \n",
    "                        a_real_mess = a_real_mess.drop_duplicates()\n",
    "                        a_real_mess.to_sql('mipacq_reference_mixed_only_new', engine, if_exists=\"append\") \n",
    "                \n",
    "                ann_to_string = ann_to_string.drop_duplicates()\n",
    "                ann_to_string.to_sql('mipacq_reference_strings_only_new', engine, if_exists=\"append\") \n",
    "                \n",
    "                strings.drop_duplicates()\n",
    "                strings.to_sql('mipacq_strings_new', engine, if_exists=\"append\")\n",
    "\n",
    "\n",
    "    print(\"n problem files:\", len(missing_key), \"empty ann:\", len(empty_annotations), \"n processed files:\", len(processed_files))\n",
    "    print(\"problem files:\", missing_key, \"empty ann:\", empty_annotations)\n",
    "\n",
    "\n",
    "#parse_mipacq_reference()\n",
    "#print('Fini!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# parse i2b2 reference standard\n",
    "def parse_i2b2_reference():\n",
    "    import glob, os, re\n",
    "    import pandas as pd\n",
    "\n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from sqlalchemy.sql import text\n",
    "    from cassis import load_typesystem, load_cas_from_xmi\n",
    "\n",
    "    # connection string\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test')\n",
    "\n",
    "    dir_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/source_data/reference_standard_for_test_data/concepts/\"\n",
    "\n",
    "    def doit(text):      \n",
    "        matches=re.findall(r'\\\"(.+?)\\\"',text)\n",
    "        # matches is now ['String 1', 'String 2', 'String3']\n",
    "        return \"|\".join(matches)\n",
    "\n",
    "    # NB: issue when n:m NOT used to delineate line:position!!!!\n",
    "    def doit2(text):      \n",
    "        matches=re.findall(r'\\d+:\\d+',text)\n",
    "        # matches is now ['String 1', 'String 2', 'String3']\n",
    "        return \"|\".join(matches)                            \n",
    "\n",
    "    for fname in glob.glob(dir_test + '*.con'):\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "\n",
    "        case = t.replace('-v1','').split('.')\n",
    "        #print(case[0])\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        with open(dir_test + t) as f:\n",
    "            test = {}\n",
    "            for line in f:\n",
    "                a = re.sub('\\|\\|', ' ', line)\n",
    "                #print(a.replace(\"c=\",\"\").replace(\"t=\",\"\"))\n",
    "                #print(doit(line).split(','))\n",
    "                #print(doit2(line))\n",
    "                s = doit(line).split('|')\n",
    "                d = doit2(line).split('|')\n",
    "\n",
    "                t = s + d\n",
    "                #print(t)\n",
    "                for i in range(len(t)):\n",
    "                    if i == 0:\n",
    "                        test[\"text\"] = t[i]\n",
    "                    elif i == 1:\n",
    "                        test[\"type\"] = t[i]\n",
    "                    elif i == 2:\n",
    "                        test[\"start_token\"] = t[i]\n",
    "                    else:\n",
    "                        test[\"end_token\"] = t[i]\n",
    "                        frames = [ df, pd.DataFrame(test, index=[0]) ]\n",
    "                        df = pd.concat(frames, ignore_index=True)\n",
    "                        df['line'], df['start'] = df['start_token'].str.split(':', 1).str\n",
    "                        _, df['end'] = df['end_token'].str.split(':', 1).str\n",
    "\n",
    "                        df[\"file\"] = case[0]\n",
    "                        df[\"corpus\"] = \"i2b2\"\n",
    "\n",
    "            # write to database\n",
    "            #print(case)\n",
    "            df.to_sql('i2b2_reference_new', engine, if_exists=\"append\") \n",
    "\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update i2b2 reference span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def get_position(str line, int length, int start_char, int end_char):\n",
    "    '''\n",
    "    get postion of hit in document\n",
    "    '''\n",
    "    l = len(line)\n",
    "    \n",
    "    if (int(l) > 0 and isinstance(start_char, int) and isinstance(end_char, int)):\n",
    "        start = length - l + start_char\n",
    "        end = length - l + end_char\n",
    "        \n",
    "        return {'start':int(start), 'end':int(end)}\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_i2b2_text_from_span(str fname, int idx_start, int idx_end, int line_n, str text):\n",
    "    import glob, os, re\n",
    "\n",
    "    #dir_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/source_data/test_data/\"\n",
    "    dir_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/source_data/test_data/\"\n",
    "    i = 1\n",
    "    idx_start = int(idx_start) \n",
    "    idx_end = int(idx_end) \n",
    "    line_n = int(line_n)\n",
    "    length = 0\n",
    "    \n",
    "    with open(dir_test + fname) as f:\n",
    "        stop = False\n",
    "        for line in f:\n",
    "            length += len(line) # cummulative length of lines processed\n",
    "            if i == line_n:\n",
    "               \n",
    "                # issue when double quotes were nested\n",
    "                if '\"' in line and \"'\" in text:\n",
    "                    text = text.replace(\"'\",\"\\\"\")\n",
    "                \n",
    "                # get full sentence up to occurance of substring\n",
    "                t = \" \".join(line.split()[0:idx_start+len(text.split())])\n",
    "                start_char = t.lower().rindex(text.lower()) # get last index of substring in string\n",
    "                end_char = start_char + len(text)\n",
    "                \n",
    "                # we've processed line of interest, so exit\n",
    "                stop = True\n",
    "                return (get_position(line, length, start_char, end_char))\n",
    "            i += 1\n",
    "            if stop:\n",
    "                break    \n",
    "                \n",
    "\n",
    "def add_span_i2b2_ref():\n",
    "    #get_i2b2_text_from_span('0333.txt')\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    # connection string\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    sql = 'SELECT * FROM test.i2b2_reference' # where file = \"0445\"'\n",
    "    df = pd.read_sql(sql, engine)\n",
    "    #df = df.sort_values(by=['line'])\n",
    "    df['offset_start'] = None\n",
    "    df['offset_end'] = None\n",
    "\n",
    "    files = []\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        fname = row['file'] + '.txt'\n",
    "        \n",
    "        if fname not in files:\n",
    "            files.append(fname)\n",
    "            print(i, fname)\n",
    "            i += 1\n",
    "            \n",
    "        span = get_i2b2_text_from_span(fname, int(row['start']), int(row['end']), int(row['line']), row['text'])\n",
    "        df.loc[df['id'] == row[\"id\"], ['offset_start']] = span['start']\n",
    "        df.loc[df['id'] == row[\"id\"], ['offset_end']] = span['end']\n",
    "        \n",
    "    df.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/i2b2_reference_offset.csv')\n",
    "    df.to_sql('i2b2_reference_offset', engine, if_exists=\"append\")\n",
    "\n",
    "    #print(df)\n",
    "\n",
    "    elapsed = (time.time() - start)\n",
    "    print(\"elapse:\", elapsed)\n",
    "\n",
    "#add_span_i2b2_ref()\n",
    "\"\"\"removing double space annotation for case 0427, due to it blowing up:\n",
    "c=\"mild symmetric left ventricular  hypertrophy\" 70:2 70:6||t=\"problem\"\n",
    "\n",
    "and 0445\n",
    "c=\"a distended 1.6 cm  non mobile stone in the neck\" 78:4 78:13||t=\"problem\"\n",
    "may fix later\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up files in all corpora\n",
    "def clean_up_notes():\n",
    "    import re, os, glob, path\n",
    "    import regex\n",
    "\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/'\n",
    "\n",
    "    #for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/period2/*.txt\"):\n",
    "\n",
    "    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/rerun_post_validation/quarantine/'\n",
    "\n",
    "    for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/rerun_post_validation/quarantine/*.txt\"):\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        u = t.split('.')[0] + '-v1.txt'\n",
    "\n",
    "        with open(fname) as f:\n",
    "            #with open('/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/rerun_post_validation/nonprintables/' + u, 'w') as f2:\n",
    "\n",
    "                # read file\n",
    "                #f1 = f.read()\n",
    "                for line in f:\n",
    "                    # for mipacq:\n",
    "                    \"\"\"\n",
    "                    ggrep --color='auto' -Pn -- '\\d+/\\d+-'\n",
    "                    ggrep --color='auto' -Pn -- '\\s+\\.+\\s+' \n",
    "                    \"\"\"\n",
    "                    regex_a = r\"\\d+/\\d+-\" # e.g. \"45/53-\" -> replace \"-\" with \" \"\n",
    "                    regex_b = r\"[^\\x00-\\x7F]\" # # i.e. unicode -> replace characters with closest ascii\n",
    "                    #regex_c = r\"\\s+\\.+\\s+\"  # e.g. \" . \" -> replace \".\" with \" \"\n",
    "                    #regex_d = r\"^\\.+\" # i.e. period alone at the beginning of a line -> replace \".\" with \" \"a\n",
    "                    #regex_e = r\"[^[:alpha:]]\" # i.e. control codes -> delete matched characters\n",
    "\n",
    "                    # find string and replace '-' if exists\n",
    "\n",
    "                    a = re.compile(regex_a)\n",
    "                    if a.search(line):\n",
    "                        match = a.findall(line)\n",
    "                        l = len(match)\n",
    "                        for i in range(len(match)):\n",
    "                            l2 = len(match[i])\n",
    "                            t = ''\n",
    "                            for j in range(l2):\n",
    "                                t += '9'\n",
    "                            #line = line.replace(match[i], match[i].replace(match[i], t))\n",
    "                            #if i == len(match) - 1 and len(match) == 2:\n",
    "                            #    print(\"match:\", i, match, f1)\n",
    "\n",
    "                    # replace if exists in file object             \n",
    "                    b = re.search(regex_b, line)\n",
    "\n",
    "                    #c = re.search(regex_c, f1)\n",
    "                    #d = re.search(regex_d, line)\n",
    "                    #e = regex.search(regex_e, line)\n",
    "\n",
    "                    if b:\n",
    "                        print(b)\n",
    "                        #print('b:', f1, re.sub('[^\\x00-\\x7F]','', f1))\n",
    "                    #line = re.sub('[^\\x00-\\x7F]','', line)\n",
    "                    #if c:\n",
    "                        #print('c:', f1, re.sub('\\s+\\.+\\s+',' ', f1))\n",
    "                    #    f1 = re.sub('\\s+\\.+\\s+',' ', f1)\n",
    "                    #if d:\n",
    "                        #print('d:', f1, re.sub('^\\.+', ' ', f1))\n",
    "                    #    f1 = re.sub('^\\.+', ' ', f1)\n",
    "                    if e:\n",
    "                        print(e)\n",
    "                        #print('e:', f1, re.sub('[^[:alpha:]]', '', f1))\n",
    "                    #line = re.sub('[^[:alpha:]]', '', line)\n",
    "\n",
    "\n",
    "                    # write to new file \n",
    "                    #if a or b or e:\n",
    "                    #f2.write(line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qumls 244196 244196\n",
      "   begin   end                         type      system     note_id    corpus  \\\n",
      "0   2574  2604  concept_jaccard_score_False  quick_umls  0000521643  fairview   \n",
      "\n",
      "   score  semtypes  \n",
      "0    1.0  {'T121'}  \n",
      "b9 561579 561579\n",
      "   begin  end                       type      system     note_id    corpus  \\\n",
      "0     38   42  biomedicus.v2.UmlsConcept  biomedicus  0002204202  fairview   \n",
      "\n",
      "  score semtypes  \n",
      "0   1.0     T121  \n",
      "clamp 118831 118831\n",
      "   begin  end                                              type system  \\\n",
      "0    376  379  edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA  clamp   \n",
      "\n",
      "      note_id    corpus score semtypes  \n",
      "0  0029014353  fairview  None     drug  \n",
      "ctakes 134511\n",
      "   begin  end             type  system     note_id    corpus  \\\n",
      "0    150  153  ctakes_mentions  ctakes  0002204202  fairview   \n",
      "\n",
      "                 semtypes  \n",
      "0  DiseaseDisorderMention  \n",
      "mm 636125 636125\n",
      "   begin  end                           type   system     note_id    corpus  \\\n",
      "0     16   27  org.metamap.uima.ts.Candidate  metamap  0002204202  fairview   \n",
      "\n",
      "  score semtypes  \n",
      "0  -901     prog  \n",
      "   begin   end                         type      system     note_id    corpus  \\\n",
      "0   2574  2604  concept_jaccard_score_False  quick_umls  0000521643  fairview   \n",
      "\n",
      "  score  semtypes  \n",
      "0     1  {'T121'}  \n"
     ]
    }
   ],
   "source": [
    "# create tables for\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "def get_analytical_set(sql):\n",
    "    \n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#GENERATE analytical tables\n",
    "\n",
    "corpus = \"'fairview'\"\n",
    "#corpus = \"'i2b2'\"\n",
    "\n",
    "semtype = False\n",
    "\n",
    "analytical_cui = pd.DataFrame()\n",
    "\n",
    "#sql = \"SELECT * FROM test.qumls_cui where corpus =\" + corpus\n",
    "#sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, similarity as score FROM concepts.qumls_all where corpus =\" + corpus\n",
    "sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, similarity as score, semtypes FROM concepts.qumls_all where corpus =\" + corpus\n",
    "\n",
    "df = get_analytical_set(sql)\n",
    "if semtype:\n",
    "    df = df[(df['semtypes'].str.contains(\"T184\"))|(df['semtypes'].str.contains(\"T047\"))|(df['semtypes'].str.contains(\"T121\") |(df['semtypes'].str.contains(\"T033\"))) |(df['semtypes'].str.contains(\"T200\")) ]\n",
    "\n",
    "print('qumls', len(df), len(get_analytical_set(sql)))\n",
    "print(df[0:1])\n",
    "\n",
    "frames = [ analytical_cui, df ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "#sql = \"SELECT * FROM test.biomedicus_cui where corpus = \" + corpus\n",
    "sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, confidence as score, tui as semtypes FROM concepts.bio_biomedicus_UmlsConcept where corpus = \" + corpus\n",
    "\n",
    "df = get_analytical_set(sql)\n",
    "if semtype:\n",
    "    df = df[(df['semtypes'].str.contains(\"T184\"))|(df['semtypes'].str.contains(\"T047\"))|(df['semtypes'].str.contains(\"T121\") | (df['semtypes'].str.contains(\"T033\")))|(df['semtypes'].str.contains(\"T200\")) ]\n",
    "\n",
    "print('b9', len(df), len(get_analytical_set(sql)))\n",
    "print(df[0:1])\n",
    "\n",
    "frames = [ analytical_cui, df ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "#sql = \"SELECT * FROM test.clamp_all_cui where corpus = \" + corpus \n",
    "sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, concept_prob as score, semantictag as semtypes FROM concepts.cla_edu_ClampNameEntityUIMA where corpus = \" + corpus\n",
    "\n",
    "\n",
    "df = get_analytical_set(sql)\n",
    "if semtype:\n",
    "    df = df[(df['semtypes'].str.contains(\"drug\"))|(df['semtypes'].str.contains(\"problem\"))]\n",
    "\n",
    "print('clamp', len(df), len(get_analytical_set(sql)))\n",
    "print(df[0:1])\n",
    "\n",
    "frames = [ analytical_cui, df ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "#sql = \"SELECT * FROM test.ctakes_all_cui where corpus = \" + corpus\n",
    "sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, SUBSTRING_INDEX(SUBSTRING_INDEX(ctakestype, ',', 7), '.', -1) as semtypes FROM concepts.ctakes_all where corpus = \" + corpus\n",
    "\n",
    "print('ctakes', len(get_analytical_set(sql)))\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "#sql = \"SELECT * FROM test.metamap_all_cui where corpus = \" + corpus \n",
    "sql = \"SELECT begin, end, `type`, `system`, note_id, corpus, score, semantictypes as semtypes FROM concepts.met_org_Candidate where corpus = \" + corpus\n",
    "\n",
    "df = get_analytical_set(sql)\n",
    "if semtype:\n",
    "    df = df[(df['semtypes'].str.contains(\"sosy\"))| (df['semtypes'].str.contains(\"dsyn\"))| (df['semtypes'].str.contains(\"phsu\") | (df['semtypes'].str.contains(\"fndg\"))) | (df['semtypes'].str.contains(\"clnd\"))]\n",
    "\n",
    "print('mm', len(df), len(get_analytical_set(sql)))\n",
    "print(df[0:1])\n",
    "\n",
    "#print(get_analytical_set(sql)[0:1])\n",
    "frames = [ analytical_cui, df ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "print(analytical_cui[0:1])\n",
    "analytical_cui.to_csv('/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/analytical_'+corpus+'_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    # get 25 random cases \n",
    "    import pandas as pd\n",
    "    \n",
    "    #sys = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq.csv')\n",
    "    sys = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_mipacq_others.csv')\n",
    "\n",
    "    #sys = sys.sample(n = 342)\n",
    "\n",
    "    notes = sys[\"note_id\"]\n",
    "\n",
    "    notes = notes.tolist()\n",
    "\n",
    "    '''\n",
    "    training_notes = ['522412787',\n",
    "     '617637585',\n",
    "     '3307880735-8',\n",
    "     '9080688558',\n",
    "     '618370565',\n",
    "     '573718188',\n",
    "     '534584',\n",
    "     '60891',\n",
    "     '62620',\n",
    "     '616172834',\n",
    "     '4130154172-4',\n",
    "     '3580478614',\n",
    "     '5024581165-5',\n",
    "     '4486835700-9',\n",
    "     '534828617',\n",
    "     '8154986253',\n",
    "     '533855209',\n",
    "     '60118',\n",
    "     '3537704982-3',\n",
    "     '617637585',\n",
    "     '60118',\n",
    "     '9045889026',\n",
    "     '8819868493-8',\n",
    "     '533698',\n",
    "     '535978760']\n",
    "     \n",
    "     '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    exclusion_notes = [\"0595040941-0\",\n",
    "\"0778429553-0\",\n",
    "\"1014681675\",\n",
    "\"2889522952-2\",\n",
    "\"3080383448-5\",\n",
    "\"3300000926-3\",\n",
    "\"3360037185-3\",\n",
    "\"3580973392\",\n",
    "\"3627629462-3\",\n",
    "\"4323116051-4\",\n",
    "\"477704053-4\",\n",
    "\"528317073\",\n",
    "\"531702602\",\n",
    "\"534061073\",\n",
    "\"54832076\",\n",
    "\"5643725437-6\",\n",
    "\"5944412090-5\",\n",
    "\"6613169476-6\",\n",
    "\"7261075903-7\",\n",
    "\"7504944368-7\",\n",
    "\"7999462393-7\",\n",
    "\"8131081430\",\n",
    "\"8171084310\",\n",
    "\"8193787896\",\n",
    "\"8295055184-8\",\n",
    "\"8823185307-8\"]\n",
    "\n",
    "    return exclusion_notes# training_notes\n",
    "print(get_training_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_matching():\n",
    "#     #print(c.matches[0:1])\n",
    "#     for m in c.matches:\n",
    "#         for p in c.partial_match:\n",
    "#             #print(m[\"ref\"].tolist())\n",
    "#             #print(\"===\")\n",
    "#             #print(p[\"ref\"].tolist())\n",
    "#             #print(\"======\")\n",
    "\n",
    "#             if set(m[\"ref\"].tolist()) == set(p[\"ref\"].tolist()):\n",
    "#                 print(\"======\")\n",
    "#             '''\n",
    "#             for k, v in m.items():\n",
    "#                 print(k.ref)\n",
    "#                 print('---')\n",
    "#                 print(k.sys)\n",
    "#                 print(\"=====\")\n",
    "#             '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "def get_metrics(int system_only, int gold_only, int gold_system_match, int system_n):\n",
    "    \"\"\"\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    class Metrics(object):\n",
    "        \"\"\"\n",
    "        metrics class \n",
    "        \"\"\"\n",
    "        def __init__(self):\n",
    "            \n",
    "            self = self    \n",
    "            self.system_only = system_only\n",
    "            self.gold_only = gold_only\n",
    "            self.gold_system_match = gold_system_match\n",
    "            self.system_n = system_n\n",
    "            \n",
    "        def get_confusion_metrics(self):\n",
    "            \"\"\"\n",
    "            compute confusion matrix measures, as per  \n",
    "            https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "            \"\"\"\n",
    "            cdef:\n",
    "                int TP, FP, FN\n",
    "                double TM\n",
    "                \n",
    "            TP = self.gold_system_match\n",
    "            FP = self.system_only\n",
    "            FN = self.gold_only\n",
    "            TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "            confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "            c = np.asarray(confusion)\n",
    "            recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "            precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "            \n",
    "            # Tignanelli Metric\n",
    "            if FN == 0:\n",
    "                TP_FN_R = TP\n",
    "            elif FN > 0:\n",
    "                TP_FN_R = TP/FN\n",
    "            \n",
    "            return F, recall, precision, TP, FP, FN, TP_FN_R, TM\n",
    "    \n",
    "    return Metrics()\n",
    "\n",
    "#F, recall, precision, TP, FP, FN, TP_FN_R, TM = get_metrics(c.system_only, c.ref_only, c.ref_system_match, c.system_n).get_confusion_metrics()\n",
    "\n",
    "#print(F[1], recall[1], precision[1], TP, FP, FN, TP_FN_R, TM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "def get_cooccurences(ref, sys, analysis_type = 'full', single_sys = False, name = None):\n",
    "    \"\"\"\n",
    "    get coocurences between system and reference; exact match; add relaxed\n",
    "    \"\"\"\n",
    "    # test cooccurences\n",
    "    class Coocurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = []\n",
    "            self.false_negatives = []\n",
    "\n",
    "    c = Coocurences()\n",
    "    \n",
    "    if analysis_type == 'entity' and single_sys:\n",
    "        cols_to_keep = ['begin', 'end', 'note_id', 'system', 'type']\n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        sys.name = name\n",
    "    elif analysis_type == 'cui' and single_sys:\n",
    "        cols_to_keep = ['cui', 'system', 'type', 'note_id']\n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        # do not overestimate FP\n",
    "        sys = sys[~sys['cui'].isnull()] \n",
    "        ref = ref[['value', 'file']].drop_duplicates()\n",
    "        ref = ref[~ref['value'].isnull()]\n",
    "        sys.name = name\n",
    "    elif analysis_type == 'full' and single_sys:\n",
    "        cols_to_keep = ['begin', 'end', 'cui', 'system', 'type', 'note_id']\n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        sys = sys[~sys['cui'].isnull()]\n",
    "        sys.name = name\n",
    "    \n",
    "\n",
    "    match_set = []\n",
    "    for row in ref.itertuples():\n",
    "\n",
    "        if analysis_type in ['full', 'entity']:\n",
    "            r_begin = int(row.start)\n",
    "            r_end = int(row.end)\n",
    "            \n",
    "        r_case = row.file\n",
    "        #r_text = row.text\n",
    "        mMatch = False\n",
    "        pMatch = False\n",
    "        \n",
    "        if analysis_type == 'full':\n",
    "            r_cui = row.value\n",
    "        \n",
    "            for r in sys.itertuples():\n",
    "                s_begin = int(r.begin)\n",
    "                s_end = int(r.end)\n",
    "                s_case = r.note_id\n",
    "                s_system = r.system\n",
    "                s_type = r.type\n",
    "                s_cui = r.cui\n",
    "\n",
    "#                 d = {'case': s_case, \n",
    "#                      'begin': s_begin, \n",
    "#                      'end': s_end, \n",
    "#                      'system': s_system, \n",
    "#                      'type': s_type}\n",
    "                \n",
    "                if (r_case == s_case) and (r_begin == s_begin) and (r_end == s_end):\n",
    "#                     if d not in match_set:\n",
    "#                         match_set.append(d)\n",
    "\n",
    "                    if (r_cui == s_cui):\n",
    "                        value = (r_begin, r_end, r_cui, r_case)\n",
    "                        if value not in c.matches:\n",
    "                            c.matches.append(value())\n",
    "                        mMatch = True\n",
    "                        break\n",
    "                        \n",
    "        elif analysis_type == 'entity':\n",
    "            \n",
    "            for r in sys.itertuples():\n",
    "                s_begin = int(r.begin)\n",
    "                s_end = int(r.end)\n",
    "                s_case = r.note_id\n",
    "                s_system = r.system\n",
    "                s_type = r.type\n",
    "\n",
    "#                 d = {'case': s_case, \n",
    "#                      'begin': s_begin, \n",
    "#                      'end': s_end, \n",
    "#                      'system': s_system, \n",
    "#                      'type': s_type}\n",
    "                \n",
    "                if (r_case == s_case) and (r_begin == s_begin) and (r_end == s_end):\n",
    "#                     if d not in match_set:\n",
    "#                         match_set.append(d)\n",
    "                    value = (r_begin, r_end, r_case)\n",
    "                    if value not in c.matches:\n",
    "                        c.matches.append(value)\n",
    "                    mMatch = True\n",
    "                    break\n",
    "                        \n",
    "        if analysis_type == 'cui':\n",
    "            r_cui = row.value\n",
    "        \n",
    "            for r in sys.itertuples():\n",
    "                #s_begin = int(r.begin)\n",
    "                #s_end = int(r.end)\n",
    "                s_case = r.note_id\n",
    "                s_system = r.system\n",
    "                s_type = r.type\n",
    "                s_cui = r.cui\n",
    "\n",
    "#                 d = {'case': s_case, \n",
    "#                      #'begin': s_begin, \n",
    "#                      #'end': s_end, \n",
    "#                      'system': s_system, \n",
    "#                      'type': s_type}\n",
    "\n",
    "                if (r_case == s_case) and (r_cui == s_cui):\n",
    "                    #if d not in match_set:\n",
    "                    #    match_set.append(d)\n",
    "                    value = (r_cui, r_case)\n",
    "                    if value not in c.matches:\n",
    "                        c.matches.append(value)\n",
    "                    mMatch = True\n",
    "                    break\n",
    "                        \n",
    "                        \n",
    "        if not mMatch:\n",
    "            if analysis_type == 'full':\n",
    "                value = (r_begin, r_end, r_cui, r_case)\n",
    "                \n",
    "            elif analysis_type == 'entity':\n",
    "                value = (r_begin, r_end, r_case)\n",
    "           \n",
    "            else:\n",
    "                value = (r_cui, r_case)\n",
    "\n",
    "            if value not in c.false_negatives:\n",
    "                c.false_negatives.append(value)\n",
    "\n",
    "            #c.false_negatives.append({\"ref\": (r_begin, r_end, r_case), \"sys\": 'fn'})\n",
    "            #print('FN')\n",
    "            c.ref_only += 1\n",
    "\n",
    "        # use for metrics \n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        #c.partial_n = len(c.partial_match)\n",
    "\n",
    "        #print('REF ONLY:', c.ref_only, len(c.false_negatives))\n",
    "        # sanity check\n",
    "        if len(ref) - c.ref_system_match < 0:\n",
    "            print(c.matches)\n",
    "    \n",
    "    # write output to file\n",
    "    dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/'\n",
    "    \n",
    "    if single_sys:\n",
    "        with open(dir_out + sys.name + '_' + analysis_type + '_matches.txt', 'w') as f:\n",
    "            for item in c.matches:\n",
    "                f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "        # write to file\n",
    "        with open(dir_out + sys.name + '_' + analysis_type + '_ref_only.txt', 'w') as f:\n",
    "            for item in c.false_negatives:\n",
    "                f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_overlaps(test, final_cut):\n",
    "    \n",
    "    for i in test:\n",
    "        for i in v:\n",
    "            if i not in final_cut:\n",
    "                final_cut.append(i)\n",
    "    \n",
    "    return final_cut\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_degree(test):\n",
    "\n",
    "    matches = []\n",
    "    no_match = []\n",
    "    Match = False\n",
    "    for i in test:\n",
    "        for k, v in i.items():\n",
    "            #print('i:', k, v)\n",
    "            if str(k) not in str(v):\n",
    "                if len(v) == 1:\n",
    "                    #print('BELOW THRESHOLD FOR OVERLAP')\n",
    "                    no_match.append((k, v))\n",
    "                    break\n",
    "                elif len(v) > 1:\n",
    "                    #print('THRESHOLD OF OVERLAP MATCH MET', k, v)\n",
    "                    Match = True\n",
    "            elif str(k) in str(v):\n",
    "                #print('EXACT!')\n",
    "                Match = True\n",
    "                break\n",
    "                \n",
    "            if Match:\n",
    "                matches.append((k, v))\n",
    "                #final_cut = in_overlaps(v)\n",
    "                #match_set = match_set + final_cut\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    #if system == 'ctakes':\n",
    "        #print('t:', len(matches), matches)\n",
    "    #    pass\n",
    "   \n",
    "    #print(matches, len(matches))\n",
    "    return Match #, match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_data(training_notes):\n",
    "    import pandas as pd\n",
    "\n",
    "    # test case: 527982345\n",
    "\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    sql = \"SELECT * FROM test.mipacq_all where file not in %(training_notes)s\"  \n",
    "    ref_ann = pd.read_sql(sql, params={\"training_notes\":training_notes}, con=engine)\n",
    "\n",
    "    #print(ref[0:10])\n",
    "\n",
    "    sys_ann = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts-pk-deduped.csv')\n",
    "    sys_ann = sys_ann[~sys_ann['note_id'].isin(training_notes)]\n",
    "\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "\n",
    "    #print(sys[0:10])\n",
    "\n",
    "    \n",
    "    return ref_ann, sys_ann\n",
    "\n",
    "#print(training_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of 2.\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy import stats\n",
    "    from scipy.stats.mstats import gmean\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    #frames = [data, metrics]\n",
    "    #data = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metrics():\n",
    "# issue with 354 annotations having double start/end attributes causing Null value\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    systems = [\"biomedicus\",\"ctakes\",\"metamap\",\"clamp\"]\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    training_notes = get_training_data()\n",
    "    ref_ann, sys_ann = get_metric_data(training_notes)\n",
    "    \n",
    "    analysis_type = 'entity'\n",
    "    \n",
    "    # klduge for ctakes\n",
    "    system_only = [] \n",
    "    ref_only = [] \n",
    "    ref_system_match = [] \n",
    "    system_n = []\n",
    "    \n",
    "    for sys in systems:\n",
    "            types, _, _ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "            for t in types:\n",
    "                print(t)\n",
    "                system = pd.DataFrame()\n",
    "                for row in sys_ann.itertuples():\n",
    "                    #print(row.system, sys) \n",
    "                    if str(row.system) == str(sys) and str(row.type) == str(t):\n",
    "                        #print(\"hi\")\n",
    "                        d = {\"begin\": row.begin,\n",
    "                             \"end\": row.end,\n",
    "                             \"system\": row.system,\n",
    "                             \"type\": row.type,\n",
    "                             #\"corpus\": row.corpus,\n",
    "                             \"note_id\": row.note_id}\n",
    "\n",
    "                        if analysis_type in ['full', 'cui']:\n",
    "                            d[\"cui\"] = row.cui\n",
    "                        #print(d)\n",
    "                              \n",
    "                        frames = [ system, pd.DataFrame(d, index=[0]) ]\n",
    "                        system = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "                        #print(len(system), len(system.drop_duplicates()))\n",
    "\n",
    "                system = system.drop_duplicates()\n",
    "                system.name = sys\n",
    "                \n",
    "                c = get_cooccurences(ref_ann, system, analysis_type, True, system.name) # get matches, FN, etc.\n",
    "                \n",
    "                print(c.ref_n, c.ref_only, c.system_n, c.system_only, c.ref_system_match)\n",
    "                \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to deictionary -> df\n",
    "                F, recall, precision, TP, FP, FN, TP_FN_R, TM = get_metrics(c.system_only, c.ref_only, c.ref_system_match, c.system_n).get_confusion_metrics()\n",
    "                d = {'system': sys, \n",
    "                     'type': t, \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': c.ref_n, \n",
    "                     'n_sys': c.system_n, \n",
    "                      #'n_partial': c.partial_n,\n",
    "                     'TM': TM}\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                #print(data)\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", t)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapse:\", sys, elapsed)\n",
    "            \n",
    "    elapsed = (time.time() - start)\n",
    "    print(geometric_mean(metrics))\n",
    "    #metrics.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/metrics_' + analysis_type + '.csv')\n",
    "    print(\"total elapsed time:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#gen_metrics()\n",
    "print('yesh!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_test(types, new, type_name, analysis_type, set_operation):\n",
    "   \n",
    "    metrics = pd.DataFrame()\n",
    "    training_notes = get_training_data()\n",
    "   \n",
    "    new = new[new['note_id'].isin(training_notes)]\n",
    "    new[\"system\"] = set_operation + '_' + analysis_type \n",
    "    new[\"type\"] = type_name\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(training_notes)\n",
    "    \n",
    "    # set analysis type\n",
    "    \n",
    "    if analysis_type == 'cui':\n",
    "        cols_to_keep = ['value', 'file']\n",
    "        ref_ann = ref_ann[cols_to_keep]\n",
    "        ref_ann = ref_ann.drop_duplicates()\n",
    "        \n",
    "    for t in types:\n",
    "        #print(t)\n",
    "        system = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        for row in new.itertuples():\n",
    "            #print(row.system, sys) \n",
    "            #if str(row.system) == str(sys) and str(row.type) == str(t):\n",
    "                #print(\"hi\")\n",
    "           \n",
    "            d = {\"system\": row.system,\n",
    "                 \"type\": row.type,\n",
    "                 #\"corpus\": row.corpus,\n",
    "                 \"note_id\": row.note_id}\n",
    "\n",
    "            if analysis_type in ['full', 'cui']:\n",
    "                d[\"cui\"] = row.cui\n",
    "            \n",
    "            if analysis_type in ['full', 'entity']:\n",
    "                d[\"begin\"] = row.begin,\n",
    "                d[\"end\"] = row.end,\n",
    "            \n",
    "            #print(d)\n",
    "\n",
    "            frames = [ system, pd.DataFrame(d, index=[0]) ]\n",
    "            system = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "        c = get_cooccurences(ref_ann, system, analysis_type) # get matches, FN, etc.\n",
    "\n",
    "        print('refn', c.ref_n, 'systemn', c.system_n, 'sysn', c.system_only, 'matchn', c.ref_system_match)\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to deictionary -> df\n",
    "        F, recall, precision, TP, FP, FN, TP_FN_R, TM = get_metrics(c.system_only, c.ref_only, c.ref_system_match, c.system_n).get_confusion_metrics()\n",
    "        d = {'system': set_operation + '_' + analysis_type, #sys, \n",
    "             'type': t, \n",
    "             'F': F[1], \n",
    "             'precision': precision[1], \n",
    "             'recall': recall[1], \n",
    "             'TP': TP, \n",
    "             'FN': FN, \n",
    "             'FP': FP, \n",
    "             'TP/FN': TP_FN_R,\n",
    "             'n_gold': c.ref_n, \n",
    "             'n_sys': c.system_n, \n",
    "              #'n_partial': c.partial_n,\n",
    "             'TM': TM}\n",
    "\n",
    "        data = pd.DataFrame(d,  index=[0])\n",
    "        #print(data)\n",
    "        metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "        #print(geometric_mean(metrics))\n",
    "        metrics.drop_duplicates(keep='last', inplace=True)\n",
    "        \n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import functools as ft\n",
    "\n",
    "def get_merges():\n",
    "    writer = pd.ExcelWriter('/Users/gms/development/nlp/nlpie/data/amia-2019/output/merged_metrics.xlsx')\n",
    "    df = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts-pk-deduped.csv')\n",
    "\n",
    "    # initialize system dataframes\n",
    "    biomedicus = df[df[\"system\"] == \"biomedicus\"].copy()\n",
    "    #print(len(biomedicus))\n",
    "    biomedicus.name = \"biomedicus\"\n",
    "\n",
    "    clamp = df[df[\"system\"] == \"clamp\"].copy()\n",
    "    #print(len(clamp))\n",
    "    clamp.name = \"clamp\"\n",
    "\n",
    "    ctakes = df[df[\"system\"] == \"ctakes\"].copy()\n",
    "    #print(len(ctakes))\n",
    "    ctakes.name = \"ctakes\"\n",
    "\n",
    "    metamap = df[df[\"system\"] == \"metamap\"].copy()\n",
    "    #print(len(metamap))\n",
    "    metamap.name = \"metamap\"\n",
    "\n",
    "    frames = [biomedicus, ctakes] #, clamp, metamap]\n",
    "\n",
    "    union = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts-pk-deduped.csv')\n",
    "    #print(len(union))\n",
    "\n",
    "    set_operations = ['union', 'intersection']\n",
    "    analysis_type = ['entity']\n",
    "\n",
    "    for s in set_operations:\n",
    "        for a in analysis_type:\n",
    "\n",
    "            print('ANALYSIS: ', a)\n",
    "            metrics = pd.DataFrame()\n",
    "            for i in range(len(frames)+1): \n",
    "                if i > 1:\n",
    "                    list_of_lists = [list(elem) for elem in list(itertools.combinations(frames,i))]\n",
    "                    types = []\n",
    "                    \n",
    "                    for l in list_of_lists:\n",
    "\n",
    "                        print([x.name for x in l]) \n",
    "\n",
    "                        type_name = \"-\".join([x.name for x in l])\n",
    "                        types.append(type_name)\n",
    "\n",
    "                        # entity only\n",
    "                        if a == 'entity':\n",
    "                            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "                        \n",
    "                        # for full\n",
    "                        if a == 'full':\n",
    "                            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "                        # for cui\n",
    "                        if a == 'cui':\n",
    "                            cols_to_keep = ['cui', 'note_id']\n",
    "\n",
    "\n",
    "                        if s == 'union':\n",
    "\n",
    "                            new_union = union[union[\"system\"].isin([x.name for x in l])].copy()\n",
    "\n",
    "                            #print([x.name for x in l])\n",
    "                            new = new_union[new_union[\"system\"].isin([x.name for x in l])].copy()\n",
    "                            new = new[cols_to_keep]\n",
    "\n",
    "                            new = new.drop_duplicates()\n",
    "                            #print(len(new), new.columns)\n",
    "\n",
    "                        if s == 'intersection':\n",
    "\n",
    "                            new = ft.reduce(lambda  left,right: pd.merge(left,right,on=cols_to_keep, how='inner'), l).copy()\n",
    "                            new = new.drop_duplicates()\n",
    "\n",
    "                        #get_metric_test(types, new, type_name, a, s)\n",
    "                        \n",
    "                        out = get_metric_test(types, new, type_name, a, s)\n",
    "                        \n",
    "                        metrics = pd.concat([metrics, out])\n",
    "                        \n",
    "                        #print(test)\n",
    "                        \n",
    "            print('metrics:', geometric_mean(metrics))\n",
    "            sn = s + '_' + a\n",
    "            geometric_mean(metrics).to_excel(writer,sheet_name=sn, engine='xlsxwriter')\n",
    "\n",
    "    print(\"fini!\")  \n",
    "    writer.save()\n",
    "    \n",
    "#get_merges()\n",
    "print(\"fini!\")  \n",
    "\n",
    "i ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cui list in clamp\n",
    "#df['stridx']=df.index\n",
    "\n",
    "\n",
    "#print(df[df['cui'].str.contains(',')==True])\n",
    "\n",
    "#df['new_cui' ] = np.where(df.cui.str.contains(','), df['cui'].str.split(r'\\s*,\\s*|\\s*\\.\\s*').str[0], df['cui'])\n",
    "\n",
    "#print(df['cui'])\n",
    "#print(df[df['cui'].str.contains(',')==False])\n",
    "\n",
    "#new = df.rename(columns={'cui': 'old_cui', 'new_cui': 'cui'}).copy() \n",
    "#new.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts_new.csv')\n",
    "#writer = pd.ExcelWriter('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble/merged_metrics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE merges\n",
    "\n",
    "# change system names and types of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data for single entity and single entity with ensemble pairing for either all unions or all intersections\n",
    "import pandas as pd\n",
    "import functools as ft\n",
    "\n",
    "def initialize_ensemble():\n",
    "    analysis_type = 'entity'\n",
    "    run_type = 'single'\n",
    "\n",
    "    # THIS CHANGES as does frame definition below\n",
    "    #systems = ['biomedicus', 'clamp'] #, 'metamap'] -> done\n",
    "    #systems = ['biomedicus', 'ctakes', 'clamp']\n",
    "    #systems = ['biomedicus', 'ctakes']\n",
    "    #systems = ['biomedicus', 'clamp']\n",
    "    #systems = ['biomedicus', 'metamap']\n",
    "    systems = ['clamp', 'ctakes']\n",
    "    #systems = ['clamp', 'metamap']\n",
    "    #systems = ['ctakes', 'metamap']\n",
    "    #systems = ['biomedicus', 'ctakes', 'clamp']\n",
    "    #systems = ['biomedicus', 'ctakes', 'metamap']\n",
    "    #systems = ['biomedicus', 'clamp', 'metamap']\n",
    "    #systems = ['clamp', 'ctakes', 'metamap']\n",
    "    #systems = ['clamp', 'ctakes', 'metamap', 'biomedicus']\n",
    "\n",
    "    #data = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts-pk-deduped.csv')\n",
    "\n",
    "    training_notes = get_training_data()\n",
    "\n",
    "    #data = data[data['note_id'].isin(training_notes)]\n",
    "    ref_ann, data = get_metric_data(training_notes)\n",
    "    \n",
    "    #print(data)\n",
    "\n",
    "    # initialize system dataframes\n",
    "    biomedicus = data[data[\"system\"] == \"biomedicus\"].copy()\n",
    "    #print(len(biomedicus))\n",
    "    biomedicus.name = \"biomedicus\"\n",
    "    \n",
    "    #print(biomedicus[biomedicus['note_id'] == '3356675305-3'].sort_values(by=['begin'])[0:20])\n",
    "\n",
    "    clamp = data[data[\"system\"] == \"clamp\"].copy()\n",
    "    #print(len(clamp))\n",
    "    clamp.name = \"clamp\"\n",
    "\n",
    "    ctakes = data[data[\"system\"] == \"ctakes\"].copy()\n",
    "    #print(len(ctakes))\n",
    "    ctakes.name = \"ctakes\"\n",
    "    #print(ctakes[ctakes['note_id'] == '3356675305-3'].sort_values(by=['begin'])[0:20])\n",
    "\n",
    "    metamap = data[data[\"system\"] == \"metamap\"].copy()\n",
    "    #print(len(metamap))\n",
    "    metamap.name = \"metamap\"\n",
    "\n",
    "    # THIS CHANGES\n",
    "    #frames = #[biomedicus, ctakes] # \n",
    "    #frames = [biomedicus, metamap]\n",
    "    #frames = [biomedicus, clamp]\n",
    "    frames = [clamp, ctakes]\n",
    "    #frames = [clamp, metamap]\n",
    "    #frames = [ctakes, metamap]\n",
    "    #frames = [biomedicus, ctakes, clamp]\n",
    "    #frames = [biomedicus, ctakes, metamap]\n",
    "    #frames = [biomedicus, clamp, metamap]\n",
    "    #frames = [clamp, ctakes, metamap]\n",
    "    #frames = [clamp, ctakes, biomedicus, metamap]\n",
    "\n",
    "    #for f in frames:\n",
    "    names = [x.name for x in frames]\n",
    "\n",
    "    #cols_to_keep = ['begin', 'end', 'note_id']\n",
    "\n",
    "    if analysis_type == 'entity':\n",
    "        cols_to_keep = ['begin', 'end', 'note_id']\n",
    "    elif analysis_type == 'cui':\n",
    "        cols_to_keep = ['cui', 'note_id']\n",
    "    elif analysis_type == 'full':\n",
    "        cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "    # union\n",
    "    union = data[data[\"system\"].isin(names)].copy()\n",
    "    union = union[cols_to_keep].drop_duplicates()\n",
    "\n",
    "    # intersect\n",
    "    intersect = ft.reduce(lambda  left,right: pd.merge(left,right,on=cols_to_keep, how='inner'), frames).copy()\n",
    "    intersect = intersect[cols_to_keep].drop_duplicates()\n",
    "\n",
    "    # do not overestimate FN\n",
    "    if analysis_type in ['cui', 'full']:\n",
    "        union = union[~union['cui'].isnull()]\n",
    "        intersect = intersect[~intersect['cui'].isnull()]\n",
    "    if analysis_type == 'cui':\n",
    "        ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        \n",
    "    system_n_union = len(union)\n",
    "    system_n_intersect = len(intersect)\n",
    "    ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "    print('len sys:', system_n_union, system_n_intersect)\n",
    "    \n",
    "    return system_n_union, system_n_intersect, ref_n, systems\n",
    "\n",
    "system_n_union, system_n_intersect, ref_n, systems = initialize_ensemble()\n",
    "print(system_n_union, system_n_intersect, ref_n, systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# get single system matches and false positives for single systems merges only\n",
    "\n",
    "print(systems)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[0]+'_entity_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "sys1_m = [ ast.literal_eval(f) for f in a ]\n",
    "\n",
    "print((sys1_m[0:1]))\n",
    "\n",
    "#print(biomedicus_m)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[0]+'_entity_ref_only.txt', 'r')\n",
    "a = file.readlines()\n",
    "sys1_r = [ ast.literal_eval(f) for f in a ]\n",
    "#print(biomedicus_r)\n",
    "\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'_entity_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "sys2_m = [ ast.literal_eval(f) for f in a ]\n",
    "\n",
    "#print(biomedicus_m)\n",
    "\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'_entity_ref_only.txt', 'r')\n",
    "a = file.readlines()\n",
    "sys2_r = [ ast.literal_eval(f) for f in a ]\n",
    "\n",
    "#print(biomedicus_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# get single system matches and false positives for merge with exising merge\n",
    "print(systems[2])\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[2]+'_entity_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "ss_m = [ ast.literal_eval(f) for f in a ]\n",
    "\n",
    "#print(a)\n",
    "\n",
    "#print(biomedicus_m)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[2]+'_entity_ref_only.txt', 'r')\n",
    "a = file.readlines()\n",
    "ss_r = [ ast.literal_eval(f) for f in a ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ensemble system matches for use with single system match\n",
    "\n",
    "#ensemble = ['biomedicus-ctakes']#, 'biomedicus-clamp', 'biomedicus-metamap', 'clamp-ctakes', 'clamp-metamap', 'ctakes-metamap']\n",
    "#ensemble = ['biomedicus-ctakes']#, 'biomedicus-clamp', 'biomedicus-metamap', 'clamp-ctakes', 'clamp-metamap', 'ctakes-metamap']\n",
    "#ensemble = ['biomedicus-clamp']\n",
    "ensemble = ['clamp-ctakes']\n",
    "# union matches\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_union_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e1_u = a\n",
    "print(a[0:1])\n",
    "\n",
    "#print(biomedicus_m)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_intersect_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e1_i = a\n",
    "print(a[0:1])\n",
    "\n",
    "# file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'entitymatches.txt', 'r')\n",
    "# a = file.readlines()\n",
    "# a = [ ast.literal_eval(f) for f in a ]\n",
    "# e2 = a\n",
    "# #print(biomedicus_m)\n",
    "\n",
    "# file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'entityref_only.txt', 'r')\n",
    "# a = file.readlines()\n",
    "# a = [ ast.literal_eval(f) for f in a ]\n",
    "# e2_r = a\n",
    "print(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pairs of ensemble system matches \n",
    "\n",
    "#ensemble = ['biomedicus-ctakes']#, 'biomedicus-clamp', 'biomedicus-metamap', 'clamp-ctakes', 'clamp-metamap', 'ctakes-metamap']\n",
    "#ensemble = ['biomedicus-ctakes']#, 'biomedicus-clamp', 'biomedicus-metamap', 'clamp-ctakes', 'clamp-metamap', 'ctakes-metamap']\n",
    "#ensemble = ['biomedicus-clamp']\n",
    "ensemble = ['clamp-ctakes']\n",
    "# union matches\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_union_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e1_u = a\n",
    "print(a[0:1])\n",
    "\n",
    "#print(biomedicus_m)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_intersect_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e1_i = a\n",
    "print(a[0:1])\n",
    "\n",
    "print(ensemble)\n",
    "\n",
    "ensemble = ['biomedicus-metamap']\n",
    "# union matches\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_union_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e2_u = a\n",
    "print(a[0:1])\n",
    "\n",
    "#print(biomedicus_m)\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_intersect_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e2_i = a\n",
    "print(a[0:1])\n",
    "\n",
    "# file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'entitymatches.txt', 'r')\n",
    "# a = file.readlines()\n",
    "# a = [ ast.literal_eval(f) for f in a ]\n",
    "# e2 = a\n",
    "# #print(biomedicus_m)\n",
    "\n",
    "# file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[1]+'entityref_only.txt', 'r')\n",
    "# a = file.readlines()\n",
    "# a = [ ast.literal_eval(f) for f in a ]\n",
    "# e2_r = a\n",
    "print(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge single systems\n",
    "namer = systems[0] + '-' + systems[1]\n",
    "# union merge:\n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'\n",
    "\n",
    "# merge matches\n",
    "union_matches = []\n",
    "\n",
    "union_matches = sys1_m.copy()\n",
    "\n",
    "print(len(union_matches))\n",
    "print(len(set(union_matches)))\n",
    "\n",
    "for c in sys2_m:\n",
    "    if c not in union_matches and c not in sys2_m:\n",
    "        union_matches.append(c)\n",
    "        \n",
    "print(len(union_matches))\n",
    "print(len(set(union_matches)))\n",
    "\n",
    "ref_system_match = len(union_matches)\n",
    "\n",
    "\n",
    "# merge false negatives\n",
    "\n",
    "union_ref = []\n",
    "\n",
    "#union_ref = sys1_r.copy()\n",
    "\n",
    "print(len(union_ref))\n",
    "print(len(set(union_ref)))\n",
    "\n",
    "for c in set(sys2_r):\n",
    "    if c not in union_ref and c not in union_matches:\n",
    "        union_ref.append(c)\n",
    "        \n",
    "print(len(set(union_ref)))\n",
    "print(len(set(union_ref)))\n",
    "\n",
    "# get non matches in false neg\n",
    "a_ref_in_match = set(sys1_r) - set(sys2_r) #item for item in sys1_r if item not in sys2_r]\n",
    "a_ = len(a_ref_in_match)\n",
    "print('a', a_)\n",
    "\n",
    "b_ref_in_match = set(sys2_r) - set(sys1_r) #[item for item in sys2_r if item not in sys1_r]\n",
    "b_ = len(b_ref_in_match)\n",
    "print('b', b_)\n",
    "\n",
    "print('ref only', len(set(a_ref_in_match)) + len(set(b_ref_in_match)))\n",
    "#ref_only = len(union_ref)\n",
    "\n",
    "ref_only = len(set(union_ref)) - ref_system_match \n",
    "print('ref only', ref_only)\n",
    "\n",
    "system_only = system_n_union - ref_system_match\n",
    "    \n",
    "\n",
    "# get metrics\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_union).get_confusion_metrics()\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_union, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "\n",
    "u = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#u.to_excel(writer,sheet_name=namer + 'union', index=False)\n",
    "u.to_csv(dir_out + namer + '_union.csv')\n",
    "\n",
    "#writer.save()\n",
    "    \n",
    "    \n",
    "with open(dir_out + namer + '_union_' + 'matches.txt', 'w') as f:\n",
    "    for item in union_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_union_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in union_ref:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "\n",
    "# intersect merge:\n",
    "\n",
    "# merge matches\n",
    "intersect_matches = []\n",
    "intersect_ref = []\n",
    "ref_in_match = []\n",
    "\n",
    "# get matches\n",
    "intersect_matches = [item for item in sys1_m if item in sys2_m]\n",
    "\n",
    "print(len(set(sys1_m).intersection(set(sys2_m))))\n",
    "print(len([item for item in sys1_m if item in sys2_m]), len([item for item in sys2_m if item in sys1_m]))\n",
    "print(len(intersect_matches))\n",
    "\n",
    "ref_system_match = len(intersect_matches)\n",
    "\n",
    "print('aa', len(set(sys1_m) - set(sys2_m)), len(set(sys2_m) - set(sys1_m)))\n",
    "\n",
    "# get non matches in false neg\n",
    "a_ref_in_match = set(sys1_r) - set(sys2_r) #item for item in sys1_r if item not in sys2_r]\n",
    "a_ = len(a_ref_in_match)\n",
    "\n",
    "b_ref_in_match = set(sys2_r) - set(sys1_r) #[item for item in sys2_r if item not in sys1_r]\n",
    "b_ = len(b_ref_in_match)\n",
    "\n",
    "#print('test:', len(set(set(sys1_r).union(set(sys2_r)))))\n",
    "\n",
    "#print('a_', a_, b_)\n",
    "\n",
    "#print('a:', len([item for item in b_ref_in_match if item in sys1_m and item not in intersect_matches]))\n",
    "#print('b:', len([item for item in a_ref_in_match if item in sys2_m and item not in intersect_matches]))\n",
    "\n",
    "\n",
    "#print(len([item for item in b_ref_in_match if item in sys1_m]) + len([item for item in a_ref_in_match if item in sys2_m]))\n",
    "#print(len([item for item in b_ref_in_match if item in sys1_m] + [item for item in a_ref_in_match if item in sys2_m]))\n",
    "#ref_system_match = ref_system_match  #+ len([item for item in b_ref_in_match if item in sys1_m and item not in intersect_matches]) \n",
    "#+ len([item for item in a_ref_in_match if item in sys2_m and item not in intersect_matches])\n",
    "\n",
    "#intersect_ref = [item for item in sys1_r if item in sys2_r]\n",
    "\n",
    "'''\n",
    "WTF?\n",
    "ref_only = len(intersect_ref)\n",
    "'''\n",
    "#ref_only = ref_n - ref_system_match\n",
    "\n",
    "ref_only = ref_n - ref_system_match \n",
    "\n",
    "print(ref_only)\n",
    "\n",
    "system_only = system_n_intersect - ref_system_match\n",
    "\n",
    "print(system_only, system_n_intersect, ref_only, ref_system_match, ref_system_match)\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, ref_system_match).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_intersect, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "i = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#i.to_excel(writer,sheet_name=namer + 'intersect', index=False)\n",
    "\n",
    "#writer.save()\n",
    "i.to_csv(dir_out + namer + '_intersect.csv')\n",
    "\n",
    "\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'matches.txt', 'w') as f:\n",
    "    for item in intersect_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in a_ref_in_match:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "        \n",
    "\"\"\"       \n",
    "            TP = self.gold_system_match\n",
    "            FP = self.system_only\n",
    "            FN = self.gold_only\n",
    "            \n",
    "            (int system_only, int gold_only, int gold_system_match, int system_n)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble and single\n",
    "\n",
    "# union merge:\n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'\n",
    "\n",
    "# merge matches\n",
    "union_matches = []\n",
    "\n",
    "union_matches = e1_u.copy()\n",
    "\n",
    "print(len(union_matches))\n",
    "\n",
    "for c in ss_m:\n",
    "    if c not in union_matches and c not in e1_u:\n",
    "        union_matches.append(c)\n",
    "        \n",
    "print(len(union_matches))\n",
    "\n",
    "ref_system_match = len(union_matches)\n",
    "\n",
    "# merge false negatives\n",
    "\n",
    "union_ref = []\n",
    "\n",
    "#union_ref = e1_r.copy()\n",
    "\n",
    "print(len(union_ref))\n",
    "\n",
    "#for c in ss_r:\n",
    "#    if c not in union_ref:\n",
    "#        union_ref.append(c)\n",
    "        \n",
    "print(len(union_ref))\n",
    "\n",
    "#ref_only = len(union_ref)\n",
    "\n",
    "ref_only = ref_n - ref_system_match\n",
    "\n",
    "system_only = system_n_union - ref_system_match\n",
    "\n",
    "# get metrics\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_union).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_union, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "namer = systems[2] + '-' + ensemble[0]\n",
    "\n",
    "u = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#u.to_excel(writer,sheet_name=namer + 'union', index=False)\n",
    "u.to_csv(dir_out + namer + '_union.csv')\n",
    "\n",
    "#writer.save()\n",
    "\n",
    "\n",
    "with open(dir_out + namer + '_union_' + 'matches.txt', 'w') as f:\n",
    "    for item in union_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_union_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in union_ref:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "# intersect merge:\n",
    "\n",
    "# merge matches\n",
    "intersect_matches = []\n",
    "intersect_ref = []\n",
    "ref_in_match = []\n",
    "\n",
    "# get matches\n",
    "intersect_matches = [item for item in e1_i if item in ss_m]\n",
    "\n",
    "print(len(set(intersect_matches)))\n",
    "\n",
    "ref_system_match = len(intersect_matches)\n",
    "\n",
    "# get non matches in false neg\n",
    "#a_ref_in_match = [item for item in e1_r if item not in ss_r]\n",
    "#a_ = len(a_ref_in_match)\n",
    "\n",
    "#b_ref_in_match = [item for item in ss_r if item not in e1_r]\n",
    "#b_ = len(b_ref_in_match)\n",
    "\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m and item not in intersect_matches]))\n",
    "#print(len([item for item in a_ref_in_match if item in ss_m and item not in intersect_matches]))\n",
    "\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m]) + len([item for item in a_ref_in_match if item in ss_m]))\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m] + [item for item in a_ref_in_match if item in ss_m]))\n",
    "#ref_system_match = ref_system_match #+ len([ite m for item in b_ref_in_match if item in e1_m]) + len([item for item in a_ref_in_match if item in ss_m])\n",
    "\n",
    "#intersect_ref = [item for item in e1_r if item in ss_r]\n",
    "#print(len(intersect_ref))\n",
    "\n",
    "#ref_only = len(intersect_ref)\n",
    "\n",
    "ref_only = ref_n - ref_system_match\n",
    "\n",
    "\n",
    "system_only = system_n_intersect - ref_system_match\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_intersect).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_intersect, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "i = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#i.to_excel(writer,sheet_name=namer + 'intersect', index=False)\n",
    "\n",
    "#writer.save()\n",
    "i.to_csv(dir_out + namer + '_intersect.csv')\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'matches.txt', 'w') as f:\n",
    "    for item in intersect_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in ref_in_match:\n",
    "        f.write(\"%s\\n\" % str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble and ensemble \n",
    "\n",
    "# union merge:\n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'\n",
    "\n",
    "# merge matches\n",
    "union_matches = []\n",
    "\n",
    "union_matches = e1_u.copy()\n",
    "\n",
    "print(len(union_matches))\n",
    "\n",
    "for c in e1_u:\n",
    "    if c not in union_matches and c not in e2_u:\n",
    "        union_matches.append(c)\n",
    "        \n",
    "print(len(union_matches))\n",
    "\n",
    "ref_system_match = len(union_matches)\n",
    "\n",
    "# merge false negatives\n",
    "\n",
    "#union_ref = []\n",
    "\n",
    "#union_ref = e1_r.copy()\n",
    "\n",
    "#print(len(union_ref))\n",
    "\n",
    "#for c in ss_r:\n",
    "#    if c not in union_ref:\n",
    "#        union_ref.append(c)\n",
    "        \n",
    "#print(len(union_ref))\n",
    "\n",
    "#ref_only = len(union_ref)\n",
    "\n",
    "ref_only = ref_n - ref_system_match\n",
    "\n",
    "system_only = system_n_union - ref_system_match\n",
    "\n",
    "# get metrics\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_union).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_union, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "namer = systems[2] + '-' + ensemble[0]\n",
    "\n",
    "u = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#u.to_excel(writer,sheet_name=namer + 'union', index=False)\n",
    "u.to_csv(dir_out + namer + '_union.csv')\n",
    "\n",
    "#writer.save()\n",
    "\n",
    "\n",
    "with open(dir_out + namer + '_union_' + 'matches.txt', 'w') as f:\n",
    "    for item in union_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_union_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in union_ref:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "# intersect merge:\n",
    "\n",
    "# merge matches\n",
    "intersect_matches = []\n",
    "intersect_ref = []\n",
    "ref_in_match = []\n",
    "\n",
    "# get matches\n",
    "intersect_matches = [item for item in e1_i if item in e2_i]\n",
    "\n",
    "print(len(set(intersect_matches)))\n",
    "\n",
    "ref_system_match = len(intersect_matches)\n",
    "\n",
    "# get non matches in false neg\n",
    "#a_ref_in_match = [item for item in e1_r if item not in ss_r]\n",
    "#a_ = len(a_ref_in_match)\n",
    "\n",
    "#b_ref_in_match = [item for item in ss_r if item not in e1_r]\n",
    "#b_ = len(b_ref_in_match)\n",
    "\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m and item not in intersect_matches]))\n",
    "#print(len([item for item in a_ref_in_match if item in ss_m and item not in intersect_matches]))\n",
    "\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m]) + len([item for item in a_ref_in_match if item in ss_m]))\n",
    "#print(len([item for item in b_ref_in_match if item in e1_m] + [item for item in a_ref_in_match if item in ss_m]))\n",
    "#ref_system_match = ref_system_match #+ len([ite m for item in b_ref_in_match if item in e1_m]) + len([item for item in a_ref_in_match if item in ss_m])\n",
    "\n",
    "#intersect_ref = [item for item in e1_r if item in ss_r]\n",
    "#print(len(intersect_ref))\n",
    "\n",
    "#ref_only = len(intersect_ref)\n",
    "\n",
    "ref_only = ref_n - ref_system_match\n",
    "\n",
    "\n",
    "system_only = system_n_intersect - ref_system_match\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_intersect).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_intersect, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "i = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#i.to_excel(writer,sheet_name=namer + 'intersect', index=False)\n",
    "\n",
    "#writer.save()\n",
    "i.to_csv(dir_out + namer + '_intersect.csv')\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'matches.txt', 'w') as f:\n",
    "    for item in intersect_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    \n",
    "with open(dir_out + namer + '_intersect_' + 'ref_only.txt', 'w') as f:\n",
    "    for item in ref_in_match:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # intersect merge:\n",
    "\n",
    "# # merge matches\n",
    "# intersect_matches = []\n",
    "# intersect_ref = []\n",
    "# ref_in_match = []\n",
    "\n",
    "# # get matches\n",
    "# intersect_matches = [item for item in biomedicus_m if item in ctakes_m]\n",
    "\n",
    "# print(len(intersect_matches))\n",
    "\n",
    "# ref_system_match = len(intersect_matches)\n",
    "\n",
    "# # get non matches in false neg\n",
    "# a_ref_in_match = [item for item in biomedicus_r if item not in ctakes_r]\n",
    "# a_ = len(a_ref_in_match)\n",
    "\n",
    "# b_ref_in_match = [item for item in ctakes_r if item not in biomedicus_r]\n",
    "# b_ = len(b_ref_in_match)\n",
    "\n",
    "# print(len([item for item in b_ref_in_match if item in biomedicus_m and item not in intersect_matches]))\n",
    "# print(len([item for item in a_ref_in_match if item in ctakes_m and item not in intersect_matches]))\n",
    "\n",
    "# print(len([item for item in b_ref_in_match if item in biomedicus_m]) + len([item for item in a_ref_in_match if item in ctakes_m]))\n",
    "# print(len([item for item in b_ref_in_match if item in biomedicus_m] + [item for item in a_ref_in_match if item in ctakes_m]))\n",
    "# ref_system_match = ref_system_match + len([item for item in b_ref_in_match if item in biomedicus_m]) + len([item for item in a_ref_in_match if item in ctakes_m])\n",
    "\n",
    "# intersect_ref = [item for item in biomedicus_r if item in ctakes_r]\n",
    "# print(len(intersect_ref))\n",
    "\n",
    "# ref_only = len(intersect_ref)\n",
    "\n",
    "# system_only = system_n_intersect - ref_system_match\n",
    "\n",
    "# d = {}\n",
    "# F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_intersect).get_confusion_metrics()\n",
    "\n",
    "# d = {\n",
    "                \n",
    "#                      'F': F[1], \n",
    "#                      'precision': precision[1], \n",
    "#                      'recall': recall[1], \n",
    "#                      'TP': TP, \n",
    "#                      'FN': FN, \n",
    "#                      'FP': FP, \n",
    "#                      'TP/FN': TP_FN_R,\n",
    "#                      'n_gold': ref_n, \n",
    "#                      'n_sys': system_n_intersect, \n",
    "#                      'TM': TM}\n",
    "# print(d)\n",
    "\n",
    "# i = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "# i.to_excel(writer,sheet_name='biomedicus-ctakes_' + 'intersect', index=False)\n",
    "\n",
    "# writer.save()\n",
    "\n",
    "# dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble/'\n",
    "    \n",
    "# with open(dir_out + 'biomedicus-ctakes' + 'intersect_' + 'matches.txt', 'w') as f:\n",
    "#     for item in intersect_matches:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "    \n",
    "# with open(dir_out + 'biomedicus-ctakes' + 'intersect_' + 'fn.txt', 'w') as f:\n",
    "#     for item in a_ref_in_match:\n",
    "#         f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob   \n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble/' \n",
    "#writer = pd.ExcelWriter(dir_out + '/ensemble_metrics.xlsx')\n",
    "files=glob.glob(dir_out + '*.csv')  \n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file in files: \n",
    "    t = os.path.basename(file)\n",
    "    t = t.replace('.csv','').replace('biomedicus','b9')\n",
    "    print(t.replace('.csv','').replace('biomedicus','b9'))\n",
    "     \n",
    "    a = pd.read_csv(file)\n",
    "    a['type'] = t\n",
    "    \n",
    "    frames = [df, a]\n",
    "    df = pd.concat(frames)\n",
    "    \n",
    "print(df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed union with intersect\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import functools as ft\n",
    "\n",
    "def initialize_ensemble_mixed_merge():\n",
    "    analysis_type = 'entity'\n",
    "\n",
    "    # THIS CHANGES as does frame definition below\n",
    "    #systems = ['biomedicus', 'ctakes', 'clamp']\n",
    "    #systems = ['biomedicus', 'ctakes', 'metamap']\n",
    "    #systems = ['biomedicus', 'clamp', 'metamap']\n",
    "    #systems = ['clamp', 'ctakes', 'metamap']\n",
    "    #systems = ['clamp', 'ctakes', 'biomedicus']\n",
    "    #systems = ['clamp', 'metamap', 'biomedicus']\n",
    "    #systems = ['clamp', 'metamap', 'ctakes']\n",
    "    #systems = ['clamp', 'ctakes', 'metamap', 'biomedicus']\n",
    "    #systems = ['clamp', 'ctakes', 'biomedicus', 'metamap']\n",
    "    #systems = ['biomedicus', 'ctakes', 'metamap', 'clamp']\n",
    "    systems = ['biomedicus', 'clamp', 'metamap', 'ctakes']\n",
    "\n",
    "    #data = pd.read_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts-pk-deduped.csv')\n",
    "\n",
    "    training_notes = get_training_data()\n",
    "\n",
    "    #data = data[data['note_id'].isin(training_notes)]\n",
    "    ref_ann, data = get_metric_data(training_notes)\n",
    "    \n",
    "    #print(data)\n",
    "\n",
    "    # initialize system dataframes\n",
    "    biomedicus = data[data[\"system\"] == \"biomedicus\"].copy()\n",
    "    #print(len(biomedicus))\n",
    "    biomedicus.name = \"biomedicus\"\n",
    "    \n",
    "    #print(biomedicus[biomedicus['note_id'] == '3356675305-3'].sort_values(by=['begin'])[0:20])\n",
    "\n",
    "    clamp = data[data[\"system\"] == \"clamp\"].copy()\n",
    "    #print(len(clamp))\n",
    "    clamp.name = \"clamp\"\n",
    "\n",
    "    ctakes = data[data[\"system\"] == \"ctakes\"].copy()\n",
    "    #print(len(ctakes))\n",
    "    ctakes.name = \"ctakes\"\n",
    "    #print(ctakes[ctakes['note_id'] == '3356675305-3'].sort_values(by=['begin'])[0:20])\n",
    "\n",
    "    metamap = data[data[\"system\"] == \"metamap\"].copy()\n",
    "    #print(len(metamap))\n",
    "    metamap.name = \"metamap\"\n",
    "\n",
    "    # THIS CHANGES\n",
    "    #frames = [biomedicus, ctakes, clamp]\n",
    "    #frames = [biomedicus, ctakes, metamap]\n",
    "    #frames = [biomedicus, clamp, metamap]\n",
    "    #frames = [clamp, ctakes, metamap]\n",
    "    #frames = [clamp, ctakes, biomedicus]\n",
    "    #frames = [clamp, metamap, biomedicus]\n",
    "    #frames = [clamp, metamap, ctakes]\n",
    "    #frames = [clamp, ctakes, metamap, biomedicus]\n",
    "    #frames = [clamp, ctakes, biomedicus, metamap]\n",
    "    #frames = [biomedicus, ctakes, metamap, clamp]\n",
    "    frames = [biomedicus, clamp, metamap, ctakes]\n",
    "\n",
    "    #for f in frames:\n",
    "    names = [x.name for x in frames]\n",
    "\n",
    "    #cols_to_keep = ['begin', 'end', 'note_id']\n",
    "\n",
    "    if analysis_type == 'entity':\n",
    "        cols_to_keep = ['begin', 'end', 'note_id']\n",
    "    elif analysis_type == 'cui':\n",
    "        cols_to_keep = ['cui', 'note_id']\n",
    "    elif analysis_type == 'full':\n",
    "        cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "    print('union', names, names[0: len(names) -1])\n",
    "    # union\n",
    "    union = data[data[\"system\"].isin(names[0: len(names)-1])].copy()\n",
    "    union = union[cols_to_keep].drop_duplicates()\n",
    "\n",
    "    # intersect\n",
    "    #intersect = ft.reduce(lambda  left,right: pd.merge(left,right,on=cols_to_keep, how='inner'), frames).copy()\n",
    "    \n",
    "    print('intersect', names, names[len(frames)-1:len(frames)])\n",
    "    \n",
    "    intersect = union.merge(frames[len(frames)-1:len(frames)][0])\n",
    "    intersect = intersect[cols_to_keep].drop_duplicates()\n",
    "\n",
    "    # do not overestimate FN\n",
    "    if analysis_type in ['cui', 'full']:\n",
    "        union = union[~union['cui'].isnull()]\n",
    "        intersect = intersect[~intersect['cui'].isnull()]\n",
    "    if analysis_type == 'cui':\n",
    "        ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        \n",
    "    system_n_union = len(union)\n",
    "    system_n_intersect = len(intersect)\n",
    "    ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "    print('len sys:', system_n_union, system_n_intersect)\n",
    "    \n",
    "    return system_n_union, system_n_intersect, ref_n, systems\n",
    "\n",
    "system_n_union, system_n_intersect, ref_n, systems = initialize_ensemble_mixed_merge()\n",
    "print(system_n_union, system_n_intersect, ref_n, systems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# get single system matches and false positives for merge with exising merge\n",
    "print(systems[3])\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/'+systems[3]+'_entity_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "ss_m = [ ast.literal_eval(f) for f in a ]\n",
    "print(systems[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ensemble union system matches for intersection to single system\n",
    "\n",
    "#ensemble = ['biomedicus-ctakes']#, 'biomedicus-clamp', 'biomedicus-metamap', 'clamp-ctakes', 'clamp-metamap', 'ctakes-metamap']\n",
    "#ensemble = ['biomedicus-ctakes', 'metamap']\n",
    "#ensemble = ['biomedicus-clamp', 'metamap']\n",
    "#ensemble = ['clamp-ctakes', 'metamap']\n",
    "#ensemble = ['clamp-ctakes', 'biomedicus']\n",
    "#ensemble = ['clamp-metamap', 'biomedicus']\n",
    "#ensemble = ['clamp-metamap', 'ctakes']\n",
    "#ensemble = ['metamap-clamp-ctakes', 'biomedicus']\n",
    "#ensemble = ['clamp-biomedicus-ctakes', 'metamap']\n",
    "#ensemble = ['metamap-biomedicus-ctakes', 'clamp']\n",
    "ensemble = ['metamap-biomedicus-clamp', 'ctakes']\n",
    "# union matches\n",
    "file = open('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'+ensemble[0]+'_union_matches.txt', 'r')\n",
    "a = file.readlines()\n",
    "a = [ ast.literal_eval(f) for f in a ]\n",
    "e1_u = a\n",
    "print(a[0:1])\n",
    "print(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble and single\n",
    "\n",
    "namer = systems[3] + '-intersect-' + 'union-of-' + ensemble[0]\n",
    "# union merge:\n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/'\n",
    "\n",
    "# intersect merge:\n",
    "\n",
    "# merge matches\n",
    "intersect_matches = []\n",
    "intersect_ref = []\n",
    "ref_in_match = []\n",
    "\n",
    "# get matches\n",
    "intersect_matches = [item for item in e1_u if item in ss_m]\n",
    "\n",
    "print(len(set(intersect_matches)))\n",
    "\n",
    "ref_system_match = len(intersect_matches)\n",
    "\n",
    "ref_only = ref_n - ref_system_match\n",
    "\n",
    "\n",
    "system_only = system_n_intersect - ref_system_match\n",
    "\n",
    "d = {}\n",
    "F, recall, precision, TP, FP, FN, TP_FN_R, TM  = get_metrics(system_only, ref_only, ref_system_match, system_n_intersect).get_confusion_metrics()\n",
    "\n",
    "d = {\n",
    "                \n",
    "                     'F': F[1], \n",
    "                     'precision': precision[1], \n",
    "                     'recall': recall[1], \n",
    "                     'TP': TP, \n",
    "                     'FN': FN, \n",
    "                     'FP': FP, \n",
    "                     'TP/FN': TP_FN_R,\n",
    "                     'n_gold': ref_n, \n",
    "                     'n_sys': system_n_intersect, \n",
    "                     'TM': TM}\n",
    "print(d)\n",
    "\n",
    "i = pd.DataFrame(d,  index=[0]) #, columns=['F','precision','recall','TP','FN','TP/FN','n_sys','TM'])\n",
    "\n",
    "#i.to_excel(writer,sheet_name=namer + 'intersect', index=False)\n",
    "\n",
    "#writer.save()\n",
    "i.to_csv(dir_out + namer + '-matches.csv')\n",
    "    \n",
    "with open(dir_out + namer + '-matches.txt', 'w') as f:\n",
    "    for item in intersect_matches:\n",
    "        f.write(\"%s\\n\" % str(item))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob   \n",
    "dir_out = '/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble_entity/' \n",
    "#writer = pd.ExcelWriter(dir_out + '/ensemble_metrics.xlsx')\n",
    "files=glob.glob(dir_out + '*.csv')  \n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file in files: \n",
    "    t = os.path.basename(file)\n",
    "    t = t.replace('.csv','').replace('biomedicus','b9')\n",
    "    #print(t.replace('.csv','').replace('biomedicus','b9'))\n",
    "     \n",
    "    a = pd.read_csv(file)\n",
    "    a['type'] = t.replace('-matches','').replace('metamap','mm').replace('-intersect','_intersect').replace('-union','_union')\n",
    "    \n",
    "    frames = [df, a]\n",
    "    df = pd.concat(frames)\n",
    "    \n",
    "#print(df)    \n",
    "geometric_mean(df).to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/fule_run_entity_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       cui  end     ngram  note_id  preferred          semtypes  \\\n",
      "0           0  C1328956   14    Health   521643          1          {'T058'}   \n",
      "1           1  C1512346   26     Visit   521643          1          {'T058'}   \n",
      "2           2  C2740799  120      Date   521643          1  {'T129', 'T121'}   \n",
      "3           3  C2024467  131      Time   521643          1          {'T033'}   \n",
      "4           4  C1555587  146  Provider   521643          1          {'T170'}   \n",
      "\n",
      "   similarity  begin      term      system similarity_name overlap     type  \\\n",
      "0    0.800000      8   eHealth  quick_umls         jaccard   score  concept   \n",
      "1    0.750000     21    Visits  quick_umls         jaccard   score  concept   \n",
      "2    1.000000    116      Date  quick_umls         jaccard   score  concept   \n",
      "3    1.000000    127      Time  quick_umls         jaccard   score  concept   \n",
      "4    0.714286    138  provider  quick_umls         jaccard   score  concept   \n",
      "\n",
      "   best_match    corpus  \n",
      "0       False  fairview  \n",
      "1       False  fairview  \n",
      "2       False  fairview  \n",
      "3       False  fairview  \n",
      "4       False  fairview  \n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.engine import create_engine\n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "df = pd.read_csv('/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/qumls_system_fv.csv')\n",
    "print(df.head())\n",
    "\n",
    "df.to_sql(\"qumls_all_data_fv\", engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
